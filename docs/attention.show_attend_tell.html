---

title: show_attend_and_tell


keywords: fastai
sidebar: home_sidebar



nb_path: "attention.show_attend_tell.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: attention.show_attend_tell.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># ! pip install pytorch</span>
<span class="c1"># ! pip install scipy==1.2.1</span>
<span class="c1"># ! pip install &#39;pillow&lt;7.0.0&#39;</span>
<span class="c1"># ! pip install torchvision</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span> rm flickr8k_op/* 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="o">.</span><span class="n">data</span><span class="o">/</span>
<span class="c1"># Loss function</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Custom dataloaders</span>
<span class="n">normalize</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span>
                                 <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">CaptionDataset</span><span class="p">(</span><span class="n">data_folder</span><span class="p">,</span> <span class="n">data_name</span><span class="p">,</span> <span class="s1">&#39;TRAIN&#39;</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">normalize</span><span class="p">])),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">CaptionDataset</span><span class="p">(</span><span class="n">data_folder</span><span class="p">,</span> <span class="n">data_name</span><span class="p">,</span> <span class="s1">&#39;VAL&#39;</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">normalize</span><span class="p">])),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-cyan-fg">  File </span><span class="ansi-green-fg">&#34;&lt;ipython-input-26-ff9fb26f9230&gt;&#34;</span><span class="ansi-cyan-fg">, line </span><span class="ansi-green-fg">4</span>
<span class="ansi-red-fg">    .data/</span>
    ^
<span class="ansi-red-fg">SyntaxError</span><span class="ansi-red-fg">:</span> invalid syntax
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">word_map_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_folder</span><span class="p">,</span> <span class="s1">&#39;WORDMAP_&#39;</span> <span class="o">+</span> <span class="n">data_name</span> <span class="o">+</span> <span class="s1">&#39;.json&#39;</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">word_map_file</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">j</span><span class="p">:</span>
    <span class="n">word_map</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">create_input_files</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="s1">&#39;flickr8k&#39;</span><span class="p">,</span>
                   <span class="n">karpathy_json_path</span><span class="o">=</span><span class="s1">&#39;.data/dataset_flickr8k.json&#39;</span><span class="p">,</span>
                   <span class="n">image_folder</span><span class="o">=</span><span class="s1">&#39;/home/vimarshc/Documents/jupyterblog/.data/flickr_data/Flickr_Data/Images/&#39;</span><span class="p">,</span>
                   <span class="n">captions_per_image</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                   <span class="n">min_word_freq</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                   <span class="n">output_folder</span><span class="o">=</span><span class="s1">&#39;.data/flickr8k_op_ii&#39;</span><span class="p">,</span>
                   <span class="n">max_len</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>  0%|          | 3/6000 [00:00&lt;03:30, 28.50it/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Reading TRAIN images and captions, storing to file...

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 6000/6000 [01:55&lt;00:00, 52.05it/s]
  0%|          | 5/1000 [00:00&lt;00:21, 46.43it/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Reading VAL images and captions, storing to file...

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 1000/1000 [00:20&lt;00:00, 49.57it/s]
  1%|          | 6/1000 [00:00&lt;00:19, 50.50it/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Reading TEST images and captions, storing to file...

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 1000/1000 [00:20&lt;00:00, 48.20it/s]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">encoder_optimizer</span><span class="p">,</span> <span class="n">decoder_optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs one epoch&#39;s training.</span>
<span class="sd">    :param train_loader: DataLoader for training data</span>
<span class="sd">    :param encoder: encoder model</span>
<span class="sd">    :param decoder: decoder model</span>
<span class="sd">    :param criterion: loss layer</span>
<span class="sd">    :param encoder_optimizer: optimizer to update encoder&#39;s weights (if fine-tuning)</span>
<span class="sd">    :param decoder_optimizer: optimizer to update decoder&#39;s weights</span>
<span class="sd">    :param epoch: epoch number</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">decoder</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>  <span class="c1"># train mode (dropout and batchnorm is used)</span>
    <span class="n">encoder</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="n">batch_time</span> <span class="o">=</span> <span class="n">AverageMeter</span><span class="p">()</span>  <span class="c1"># forward prop. + back prop. time</span>
    <span class="n">data_time</span> <span class="o">=</span> <span class="n">AverageMeter</span><span class="p">()</span>  <span class="c1"># data loading time</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="n">AverageMeter</span><span class="p">()</span>  <span class="c1"># loss (per word decoded)</span>
    <span class="n">top5accs</span> <span class="o">=</span> <span class="n">AverageMeter</span><span class="p">()</span>  <span class="c1"># top5 accuracy</span>

    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="c1"># Batches</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="n">caps</span><span class="p">,</span> <span class="n">caplens</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">data_time</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>
        <span class="c1"># Move to GPU, if available</span>
        <span class="n">imgs</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">caps</span> <span class="o">=</span> <span class="n">caps</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">caplens</span> <span class="o">=</span> <span class="n">caplens</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Forward prop.</span>
        <span class="n">imgs</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>
        <span class="n">scores</span><span class="p">,</span> <span class="n">caps_sorted</span><span class="p">,</span> <span class="n">decode_lengths</span><span class="p">,</span> <span class="n">alphas</span><span class="p">,</span> <span class="n">sort_ind</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="n">caps</span><span class="p">,</span> <span class="n">caplens</span><span class="p">)</span>

        <span class="c1"># Since we decoded starting with &lt;start&gt;, the targets are all words after &lt;start&gt;, up to &lt;end&gt;</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="n">caps_sorted</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>

        <span class="c1"># Remove timesteps that we didn&#39;t decode at, or are pads</span>
        <span class="c1"># pack_padded_sequence is an easy trick to do this</span>
        <span class="n">scores</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">pack_padded_sequence</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">decode_lengths</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">targets</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">pack_padded_sequence</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">decode_lengths</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Calculate loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>

        <span class="c1"># Add doubly stochastic attention regularization</span>
        <span class="n">loss</span> <span class="o">+=</span> <span class="n">alpha_c</span> <span class="o">*</span> <span class="p">((</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alphas</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="c1"># Back prop.</span>
        <span class="n">decoder_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">encoder_optimizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">encoder_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># Clip gradients</span>
        <span class="k">if</span> <span class="n">grad_clip</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">clip_gradient</span><span class="p">(</span><span class="n">decoder_optimizer</span><span class="p">,</span> <span class="n">grad_clip</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">encoder_optimizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">clip_gradient</span><span class="p">(</span><span class="n">encoder_optimizer</span><span class="p">,</span> <span class="n">grad_clip</span><span class="p">)</span>

        <span class="c1"># Update weights</span>
        <span class="n">decoder_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">encoder_optimizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">encoder_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># Keep track of metrics</span>
        <span class="n">top5</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="n">losses</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="nb">sum</span><span class="p">(</span><span class="n">decode_lengths</span><span class="p">))</span>
        <span class="n">top5accs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">top5</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">decode_lengths</span><span class="p">))</span>
        <span class="n">batch_time</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>

        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="c1"># Print status</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">print_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch: [</span><span class="si">{0}</span><span class="s1">][</span><span class="si">{1}</span><span class="s1">/</span><span class="si">{2}</span><span class="s1">]</span><span class="se">\t</span><span class="s1">&#39;</span>
                  <span class="s1">&#39;Batch Time </span><span class="si">{batch_time.val:.3f}</span><span class="s1"> (</span><span class="si">{batch_time.avg:.3f}</span><span class="s1">)</span><span class="se">\t</span><span class="s1">&#39;</span>
                  <span class="s1">&#39;Data Load Time </span><span class="si">{data_time.val:.3f}</span><span class="s1"> (</span><span class="si">{data_time.avg:.3f}</span><span class="s1">)</span><span class="se">\t</span><span class="s1">&#39;</span>
                  <span class="s1">&#39;Loss </span><span class="si">{loss.val:.4f}</span><span class="s1"> (</span><span class="si">{loss.avg:.4f}</span><span class="s1">)</span><span class="se">\t</span><span class="s1">&#39;</span>
                  <span class="s1">&#39;Top-5 Accuracy </span><span class="si">{top5.val:.3f}</span><span class="s1"> (</span><span class="si">{top5.avg:.3f}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span>
                                                                          <span class="n">batch_time</span><span class="o">=</span><span class="n">batch_time</span><span class="p">,</span>
                                                                          <span class="n">data_time</span><span class="o">=</span><span class="n">data_time</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">losses</span><span class="p">,</span>
                                                                          <span class="n">top5</span><span class="o">=</span><span class="n">top5accs</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">h5py</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">transform</span><span class="p">,</span><span class="n">io</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">seed</span><span class="p">,</span> <span class="n">choice</span><span class="p">,</span> <span class="n">sample</span>


<span class="k">def</span> <span class="nf">create_input_files</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">karpathy_json_path</span><span class="p">,</span> <span class="n">image_folder</span><span class="p">,</span> <span class="n">captions_per_image</span><span class="p">,</span> <span class="n">min_word_freq</span><span class="p">,</span> <span class="n">output_folder</span><span class="p">,</span>
                       <span class="n">max_len</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates input files for training, validation, and test data.</span>
<span class="sd">    :param dataset: name of dataset, one of &#39;coco&#39;, &#39;flickr8k&#39;, &#39;flickr30k&#39;</span>
<span class="sd">    :param karpathy_json_path: path of Karpathy JSON file with splits and captions</span>
<span class="sd">    :param image_folder: folder with downloaded images</span>
<span class="sd">    :param captions_per_image: number of captions to sample per image</span>
<span class="sd">    :param min_word_freq: words occuring less frequently than this threshold are binned as &lt;unk&gt;s</span>
<span class="sd">    :param output_folder: folder to save files</span>
<span class="sd">    :param max_len: don&#39;t sample captions longer than this length</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">assert</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="p">{</span><span class="s1">&#39;coco&#39;</span><span class="p">,</span> <span class="s1">&#39;flickr8k&#39;</span><span class="p">,</span> <span class="s1">&#39;flickr30k&#39;</span><span class="p">}</span>
    

    <span class="c1"># Read Karpathy JSON</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">karpathy_json_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">j</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>

    <span class="c1"># Read image paths and captions for each image</span>
    <span class="n">train_image_paths</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">train_image_captions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">val_image_paths</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">val_image_captions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">test_image_paths</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">test_image_captions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">word_freq</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;images&#39;</span><span class="p">]:</span>
        <span class="n">captions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">img</span><span class="p">[</span><span class="s1">&#39;sentences&#39;</span><span class="p">]:</span>
            <span class="c1"># Update word frequency</span>
            <span class="n">word_freq</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="s1">&#39;tokens&#39;</span><span class="p">])</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="s1">&#39;tokens&#39;</span><span class="p">])</span> <span class="o">&lt;=</span> <span class="n">max_len</span><span class="p">:</span>
                <span class="n">captions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="s1">&#39;tokens&#39;</span><span class="p">])</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">captions</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">image_folder</span><span class="p">,</span> <span class="n">img</span><span class="p">[</span><span class="s1">&#39;filepath&#39;</span><span class="p">],</span> <span class="n">img</span><span class="p">[</span><span class="s1">&#39;filename&#39;</span><span class="p">])</span> <span class="k">if</span> <span class="n">dataset</span> <span class="o">==</span> <span class="s1">&#39;coco&#39;</span> <span class="k">else</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="n">image_folder</span><span class="p">,</span> <span class="n">img</span><span class="p">[</span><span class="s1">&#39;filename&#39;</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">img</span><span class="p">[</span><span class="s1">&#39;split&#39;</span><span class="p">]</span> <span class="ow">in</span> <span class="p">{</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;restval&#39;</span><span class="p">}:</span>
            <span class="n">train_image_paths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
            <span class="n">train_image_captions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">captions</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">img</span><span class="p">[</span><span class="s1">&#39;split&#39;</span><span class="p">]</span> <span class="ow">in</span> <span class="p">{</span><span class="s1">&#39;val&#39;</span><span class="p">}:</span>
            <span class="n">val_image_paths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
            <span class="n">val_image_captions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">captions</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">img</span><span class="p">[</span><span class="s1">&#39;split&#39;</span><span class="p">]</span> <span class="ow">in</span> <span class="p">{</span><span class="s1">&#39;test&#39;</span><span class="p">}:</span>
            <span class="n">test_image_paths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
            <span class="n">test_image_captions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">captions</span><span class="p">)</span>

            
    
    <span class="c1"># Sanity check</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_image_paths</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_image_captions</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_image_paths</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_image_captions</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_image_paths</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_image_captions</span><span class="p">)</span>
    

    <span class="c1"># Create word map</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">word_freq</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="n">word_freq</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">min_word_freq</span><span class="p">]</span>
    <span class="n">word_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">v</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">words</span><span class="p">)}</span>
    <span class="n">word_map</span><span class="p">[</span><span class="s1">&#39;&lt;unk&gt;&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_map</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">word_map</span><span class="p">[</span><span class="s1">&#39;&lt;start&gt;&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_map</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">word_map</span><span class="p">[</span><span class="s1">&#39;&lt;end&gt;&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_map</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">word_map</span><span class="p">[</span><span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Create a base/root name for all output files</span>
    <span class="n">base_filename</span> <span class="o">=</span> <span class="n">dataset</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">captions_per_image</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;_cap_per_img_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">min_word_freq</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;_min_word_freq&#39;</span>

    <span class="c1"># Save word map to a JSON</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_folder</span><span class="p">,</span> <span class="s1">&#39;WORDMAP_&#39;</span> <span class="o">+</span> <span class="n">base_filename</span> <span class="o">+</span> <span class="s1">&#39;.json&#39;</span><span class="p">),</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">j</span><span class="p">:</span>
        <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">word_map</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>

    <span class="c1"># Sample captions for each image, save images to HDF5 file, and captions and their lengths to JSON files</span>
    <span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">impaths</span><span class="p">,</span> <span class="n">imcaps</span><span class="p">,</span> <span class="n">split</span> <span class="ow">in</span> <span class="p">[(</span><span class="n">train_image_paths</span><span class="p">,</span> <span class="n">train_image_captions</span><span class="p">,</span> <span class="s1">&#39;TRAIN&#39;</span><span class="p">),</span>
                                   <span class="p">(</span><span class="n">val_image_paths</span><span class="p">,</span> <span class="n">val_image_captions</span><span class="p">,</span> <span class="s1">&#39;VAL&#39;</span><span class="p">),</span>
                                   <span class="p">(</span><span class="n">test_image_paths</span><span class="p">,</span> <span class="n">test_image_captions</span><span class="p">,</span> <span class="s1">&#39;TEST&#39;</span><span class="p">)]:</span>

        <span class="k">with</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_folder</span><span class="p">,</span> <span class="n">split</span> <span class="o">+</span> <span class="s1">&#39;_IMAGES_&#39;</span> <span class="o">+</span> <span class="n">base_filename</span> <span class="o">+</span> <span class="s1">&#39;.hdf5&#39;</span><span class="p">),</span> <span class="s1">&#39;a&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">h</span><span class="p">:</span>
            <span class="c1"># Make a note of the number of captions we are sampling per image</span>
            <span class="n">h</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;captions_per_image&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">captions_per_image</span>

            <span class="c1"># Create dataset inside HDF5 file to store images</span>
            <span class="n">images</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">create_dataset</span><span class="p">(</span><span class="s1">&#39;images&#39;</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">impaths</span><span class="p">),</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;uint8&#39;</span><span class="p">)</span>

            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Reading </span><span class="si">%s</span><span class="s2"> images and captions, storing to file...</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">split</span><span class="p">)</span>

            <span class="n">enc_captions</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">caplens</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">path</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="n">impaths</span><span class="p">)):</span>

                <span class="c1"># Sample captions</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">imcaps</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">captions_per_image</span><span class="p">:</span>
                    <span class="n">captions</span> <span class="o">=</span> <span class="n">imcaps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">choice</span><span class="p">(</span><span class="n">imcaps</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">captions_per_image</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">imcaps</span><span class="p">[</span><span class="n">i</span><span class="p">]))]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">captions</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">imcaps</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">k</span><span class="o">=</span><span class="n">captions_per_image</span><span class="p">)</span>

                <span class="c1"># Sanity check</span>
                <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">captions</span><span class="p">)</span> <span class="o">==</span> <span class="n">captions_per_image</span>

                <span class="c1"># Read images</span>
                <span class="n">img</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">impaths</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
                    <span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">img</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">img</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">img</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>
                <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="k">assert</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
                <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">255</span>

                <span class="c1"># Save image to HDF5 file</span>
                <span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">img</span>

                <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">captions</span><span class="p">):</span>
                    <span class="c1"># Encode captions</span>
                    <span class="n">enc_c</span> <span class="o">=</span> <span class="p">[</span><span class="n">word_map</span><span class="p">[</span><span class="s1">&#39;&lt;start&gt;&#39;</span><span class="p">]]</span> <span class="o">+</span> <span class="p">[</span><span class="n">word_map</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">word_map</span><span class="p">[</span><span class="s1">&#39;&lt;unk&gt;&#39;</span><span class="p">])</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">c</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
                        <span class="n">word_map</span><span class="p">[</span><span class="s1">&#39;&lt;end&gt;&#39;</span><span class="p">]]</span> <span class="o">+</span> <span class="p">[</span><span class="n">word_map</span><span class="p">[</span><span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">]]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">))</span>

                    <span class="c1"># Find caption lengths</span>
                    <span class="n">c_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span>

                    <span class="n">enc_captions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">enc_c</span><span class="p">)</span>
                    <span class="n">caplens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">c_len</span><span class="p">)</span>

            <span class="c1"># Sanity check</span>
            <span class="k">assert</span> <span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">captions_per_image</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">enc_captions</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">caplens</span><span class="p">)</span>

            <span class="c1"># Save encoded captions and their lengths to JSON files</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_folder</span><span class="p">,</span> <span class="n">split</span> <span class="o">+</span> <span class="s1">&#39;_CAPTIONS_&#39;</span> <span class="o">+</span> <span class="n">base_filename</span> <span class="o">+</span> <span class="s1">&#39;.json&#39;</span><span class="p">),</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">j</span><span class="p">:</span>
                <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">enc_captions</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>

            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_folder</span><span class="p">,</span> <span class="n">split</span> <span class="o">+</span> <span class="s1">&#39;_CAPLENS_&#39;</span> <span class="o">+</span> <span class="n">base_filename</span> <span class="o">+</span> <span class="s1">&#39;.json&#39;</span><span class="p">),</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">j</span><span class="p">:</span>
                <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">caplens</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">init_embedding</span><span class="p">(</span><span class="n">embeddings</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fills embedding tensor with values from the uniform distribution.</span>
<span class="sd">    :param embeddings: embedding tensor</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">3.0</span> <span class="o">/</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="o">-</span><span class="n">bias</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">load_embeddings</span><span class="p">(</span><span class="n">emb_file</span><span class="p">,</span> <span class="n">word_map</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates an embedding tensor for the specified word map, for loading into the model.</span>
<span class="sd">    :param emb_file: file containing embeddings (stored in GloVe format)</span>
<span class="sd">    :param word_map: word map</span>
<span class="sd">    :return: embeddings in the same order as the words in the word map, dimension of embeddings</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Find embedding dimension</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">emb_file</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">emb_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="n">vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">word_map</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="c1"># Create tensor to hold embeddings, initialize</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">emb_dim</span><span class="p">)</span>
    <span class="n">init_embedding</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>

    <span class="c1"># Read embedding file</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Loading embeddings...&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="n">emb_file</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">):</span>
        <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span>

        <span class="n">emb_word</span> <span class="o">=</span> <span class="n">line</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">embedding</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">n</span><span class="p">:</span> <span class="n">n</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">n</span><span class="o">.</span><span class="n">isspace</span><span class="p">(),</span> <span class="n">line</span><span class="p">[</span><span class="mi">1</span><span class="p">:])))</span>

        <span class="c1"># Ignore word if not in train_vocab</span>
        <span class="k">if</span> <span class="n">emb_word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="n">embeddings</span><span class="p">[</span><span class="n">word_map</span><span class="p">[</span><span class="n">emb_word</span><span class="p">]]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">emb_dim</span>


<span class="k">def</span> <span class="nf">clip_gradient</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">grad_clip</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Clips gradients computed during backpropagation to avoid explosion of gradients.</span>
<span class="sd">    :param optimizer: optimizer with the gradients to be clipped</span>
<span class="sd">    :param grad_clip: clip value</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">group</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="o">-</span><span class="n">grad_clip</span><span class="p">,</span> <span class="n">grad_clip</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">save_checkpoint</span><span class="p">(</span><span class="n">data_name</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">epochs_since_improvement</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">encoder_optimizer</span><span class="p">,</span> <span class="n">decoder_optimizer</span><span class="p">,</span>
                    <span class="n">bleu4</span><span class="p">,</span> <span class="n">is_best</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Saves model checkpoint.</span>
<span class="sd">    :param data_name: base name of processed dataset</span>
<span class="sd">    :param epoch: epoch number</span>
<span class="sd">    :param epochs_since_improvement: number of epochs since last improvement in BLEU-4 score</span>
<span class="sd">    :param encoder: encoder model</span>
<span class="sd">    :param decoder: decoder model</span>
<span class="sd">    :param encoder_optimizer: optimizer to update encoder&#39;s weights, if fine-tuning</span>
<span class="sd">    :param decoder_optimizer: optimizer to update decoder&#39;s weights</span>
<span class="sd">    :param bleu4: validation BLEU-4 score for this epoch</span>
<span class="sd">    :param is_best: is this checkpoint the best so far?</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">state</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
             <span class="s1">&#39;epochs_since_improvement&#39;</span><span class="p">:</span> <span class="n">epochs_since_improvement</span><span class="p">,</span>
             <span class="s1">&#39;bleu-4&#39;</span><span class="p">:</span> <span class="n">bleu4</span><span class="p">,</span>
             <span class="s1">&#39;encoder&#39;</span><span class="p">:</span> <span class="n">encoder</span><span class="p">,</span>
             <span class="s1">&#39;decoder&#39;</span><span class="p">:</span> <span class="n">decoder</span><span class="p">,</span>
             <span class="s1">&#39;encoder_optimizer&#39;</span><span class="p">:</span> <span class="n">encoder_optimizer</span><span class="p">,</span>
             <span class="s1">&#39;decoder_optimizer&#39;</span><span class="p">:</span> <span class="n">decoder_optimizer</span><span class="p">}</span>
    <span class="n">filename</span> <span class="o">=</span> <span class="s1">&#39;checkpoint_&#39;</span> <span class="o">+</span> <span class="n">data_name</span> <span class="o">+</span> <span class="s1">&#39;.pth.tar&#39;</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
    <span class="c1"># If this checkpoint is the best so far, store a copy so it doesn&#39;t get overwritten by a worse checkpoint</span>
    <span class="k">if</span> <span class="n">is_best</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="s1">&#39;BEST_&#39;</span> <span class="o">+</span> <span class="n">filename</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">AverageMeter</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Keeps track of most recent, average, sum, and count of a metric.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">avg</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val</span> <span class="o">=</span> <span class="n">val</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sum</span> <span class="o">+=</span> <span class="n">val</span> <span class="o">*</span> <span class="n">n</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">+=</span> <span class="n">n</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">avg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sum</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span>


<span class="k">def</span> <span class="nf">adjust_learning_rate</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">shrink_factor</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Shrinks learning rate by a specified factor.</span>
<span class="sd">    :param optimizer: optimizer whose learning rate must be shrunk.</span>
<span class="sd">    :param shrink_factor: factor in interval (0, 1) to multiply learning rate with.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">DECAYING learning rate.&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">param_group</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
        <span class="n">param_group</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">param_group</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">shrink_factor</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The new learning rate is </span><span class="si">%f</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">],))</span>


<span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes top-k accuracy, from predicted and true labels.</span>
<span class="sd">    :param scores: scores from the model</span>
<span class="sd">    :param targets: true labels</span>
<span class="sd">    :param k: k in top-k accuracy</span>
<span class="sd">    :return: top-k accuracy</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">ind</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="n">ind</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">ind</span><span class="p">))</span>
    <span class="n">correct_total</span> <span class="o">=</span> <span class="n">correct</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>  <span class="c1"># 0D tensor</span>
    <span class="k">return</span> <span class="n">correct_total</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="p">(</span><span class="mf">100.0</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ls</span> 
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>00_core.ipynb                          important_deep_learning_resources.ipynb
<span class="ansi-blue-intense-fg ansi-bold">assets</span>/                                index.ipynb
attention.align_and_translate.ipynb    <span class="ansi-blue-intense-fg ansi-bold">jupyterblog</span>/
attention.annotated_transformer.ipynb  LICENSE
attention.attention.ipynb              Makefile
attention.show_attend_tell.ipynb       MANIFEST.in
CONTRIBUTING.md                        other_fun_things.ipynb
divide_and_conquer.ipynb               README.md
docker-compose.yml                     scratch.ipynb
<span class="ansi-blue-intense-fg ansi-bold">docs</span>/                                  settings.ini
filesystem.ipynb                       setup.py
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">torch.backends.cudnn</span> <span class="k">as</span> <span class="nn">cudnn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span>
<span class="kn">import</span> <span class="nn">torch.utils.data</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.nn.utils.rnn</span> <span class="kn">import</span> <span class="n">pack_padded_sequence</span>
<span class="kn">from</span> <span class="nn">nltk.translate.bleu_score</span> <span class="kn">import</span> <span class="n">corpus_bleu</span>

<span class="c1"># Data parameters</span>
<span class="n">data_folder</span> <span class="o">=</span> <span class="s1">&#39;.data/flickr8k_op&#39;</span>  <span class="c1"># folder with data files saved by create_input_files.py</span>
<span class="n">data_name</span> <span class="o">=</span> <span class="s1">&#39;flickr8k_5_cap_per_img_5_min_word_freq&#39;</span>  <span class="c1"># base name shared by data files</span>

<span class="c1"># Model parameters</span>
<span class="n">emb_dim</span> <span class="o">=</span> <span class="mi">512</span>  <span class="c1"># dimension of word embeddings</span>
<span class="n">attention_dim</span> <span class="o">=</span> <span class="mi">512</span>  <span class="c1"># dimension of attention linear layers</span>
<span class="n">decoder_dim</span> <span class="o">=</span> <span class="mi">512</span>  <span class="c1"># dimension of decoder RNN</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>  <span class="c1"># sets device for model and PyTorch tensors</span>
<span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># set to true only if inputs to model are fixed size; otherwise lot of computational overhead</span>

<span class="c1"># Training parameters</span>
<span class="n">start_epoch</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">120</span>  <span class="c1"># number of epochs to train for (if early stopping is not triggered)</span>
<span class="n">epochs_since_improvement</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># keeps track of number of epochs since there&#39;s been an improvement in validation BLEU</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">workers</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># for data-loading; right now, only 1 works with h5py</span>
<span class="n">encoder_lr</span> <span class="o">=</span> <span class="mf">1e-4</span>  <span class="c1"># learning rate for encoder if fine-tuning</span>
<span class="n">decoder_lr</span> <span class="o">=</span> <span class="mf">4e-4</span>  <span class="c1"># learning rate for decoder</span>
<span class="n">grad_clip</span> <span class="o">=</span> <span class="mf">5.</span>  <span class="c1"># clip gradients at an absolute value of</span>
<span class="n">alpha_c</span> <span class="o">=</span> <span class="mf">1.</span>  <span class="c1"># regularization parameter for &#39;doubly stochastic attention&#39;, as in the paper</span>
<span class="n">best_bleu4</span> <span class="o">=</span> <span class="mf">0.</span>  <span class="c1"># BLEU-4 score right now</span>
<span class="n">print_freq</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># print training/validation stats every __ batches</span>
<span class="n">fine_tune_encoder</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># fine-tune encoder?</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># path to checkpoint, None if none</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/vimarshc/anaconda3/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() &gt; 0
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">torch.backends.cudnn</span> <span class="k">as</span> <span class="nn">cudnn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span>
<span class="kn">import</span> <span class="nn">torch.utils.data</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.nn.utils.rnn</span> <span class="kn">import</span> <span class="n">pack_padded_sequence</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">import</span> <span class="nn">h5py</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="k">class</span> <span class="nc">CaptionDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A PyTorch Dataset class to be used in a PyTorch DataLoader to create batches.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_folder</span><span class="p">,</span> <span class="n">data_name</span><span class="p">,</span> <span class="n">split</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param data_folder: folder where data files are stored</span>
<span class="sd">        :param data_name: base name of processed datasets</span>
<span class="sd">        :param split: split, one of &#39;TRAIN&#39;, &#39;VAL&#39;, or &#39;TEST&#39;</span>
<span class="sd">        :param transform: image transform pipeline</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="o">=</span> <span class="n">split</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="ow">in</span> <span class="p">{</span><span class="s1">&#39;TRAIN&#39;</span><span class="p">,</span> <span class="s1">&#39;VAL&#39;</span><span class="p">,</span> <span class="s1">&#39;TEST&#39;</span><span class="p">}</span>

        <span class="c1"># Open hdf5 file where images are stored</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_folder</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="o">+</span> <span class="s1">&#39;_IMAGES_&#39;</span> <span class="o">+</span> <span class="n">data_name</span> <span class="o">+</span> <span class="s1">&#39;.hdf5&#39;</span><span class="p">),</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">imgs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="s1">&#39;images&#39;</span><span class="p">]</span>

        <span class="c1"># Captions per image</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cpi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;captions_per_image&#39;</span><span class="p">]</span>

        <span class="c1"># Load encoded captions (completely into memory)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_folder</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="o">+</span> <span class="s1">&#39;_CAPTIONS_&#39;</span> <span class="o">+</span> <span class="n">data_name</span> <span class="o">+</span> <span class="s1">&#39;.json&#39;</span><span class="p">),</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">j</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">captions</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>

        <span class="c1"># Load caption lengths (completely into memory)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_folder</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="o">+</span> <span class="s1">&#39;_CAPLENS_&#39;</span> <span class="o">+</span> <span class="n">data_name</span> <span class="o">+</span> <span class="s1">&#39;.json&#39;</span><span class="p">),</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">j</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">caplens</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>

        <span class="c1"># PyTorch transformation pipeline for the image (normalizing, etc.)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>

        <span class="c1"># Total number of datapoints</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">captions</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="c1"># Remember, the Nth caption corresponds to the (N // captions_per_image)th image</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">imgs</span><span class="p">[</span><span class="n">i</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpi</span><span class="p">]</span> <span class="o">/</span> <span class="mf">255.</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

        <span class="n">caption</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">captions</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

        <span class="n">caplen</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">caplens</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="ow">is</span> <span class="s1">&#39;TRAIN&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">img</span><span class="p">,</span> <span class="n">caption</span><span class="p">,</span> <span class="n">caplen</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># For validation of testing, also return all &#39;captions_per_image&#39; captions to find BLEU-4 score</span>
            <span class="n">all_captions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">captions</span><span class="p">[((</span><span class="n">i</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpi</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpi</span><span class="p">):(((</span><span class="n">i</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpi</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpi</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpi</span><span class="p">)])</span>
            <span class="k">return</span> <span class="n">img</span><span class="p">,</span> <span class="n">caption</span><span class="p">,</span> <span class="n">caplen</span><span class="p">,</span> <span class="n">all_captions</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_size</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>&lt;&gt;:53: SyntaxWarning: &#34;is&#34; with a literal. Did you mean &#34;==&#34;?
&lt;&gt;:53: SyntaxWarning: &#34;is&#34; with a literal. Did you mean &#34;==&#34;?
&lt;ipython-input-14-48b5327a0544&gt;:53: SyntaxWarning: &#34;is&#34; with a literal. Did you mean &#34;==&#34;?
  if self.split is &#39;TRAIN&#39;:
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Encoder.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoded_image_size</span><span class="o">=</span><span class="mi">14</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc_image_size</span> <span class="o">=</span> <span class="n">encoded_image_size</span>

        <span class="n">resnet</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">resnet101</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># pretrained ImageNet ResNet-101</span>

        <span class="c1"># Remove linear and pool layers (since we&#39;re not doing classification)</span>
        <span class="n">modules</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">resnet</span><span class="o">.</span><span class="n">children</span><span class="p">())[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resnet</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">modules</span><span class="p">)</span>

        <span class="c1"># Resize image to fixed size to allow input images of variable size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">adaptive_pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="n">encoded_image_size</span><span class="p">,</span> <span class="n">encoded_image_size</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">fine_tune</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward propagation.</span>
<span class="sd">        :param images: images, a tensor of dimensions (batch_size, 3, image_size, image_size)</span>
<span class="sd">        :return: encoded images</span>
<span class="sd">        &quot;&quot;&quot;</span>
<span class="c1">#         import pdb;pdb.set_trace()</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resnet</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>  <span class="c1"># (batch_size, 2048, image_size/32, image_size/32)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">adaptive_pool</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>  <span class="c1"># (batch_size, 2048, encoded_image_size, encoded_image_size)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># (batch_size, encoded_image_size, encoded_image_size, 2048)</span>
        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span> <span class="nf">fine_tune</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fine_tune</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Allow or prevent the computation of gradients for convolutional blocks 2 through 4 of the encoder.</span>
<span class="sd">        :param fine_tune: Allow?</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">resnet</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="c1"># If fine-tuning, only fine-tune convolutional blocks 2 through 4</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">resnet</span><span class="o">.</span><span class="n">children</span><span class="p">())[</span><span class="mi">5</span><span class="p">:]:</span>
            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">c</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="n">fine_tune</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torchvision</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>



<span class="k">class</span> <span class="nc">Attention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Attention Network.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_dim</span><span class="p">,</span> <span class="n">decoder_dim</span><span class="p">,</span> <span class="n">attention_dim</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param encoder_dim: feature size of encoded images</span>
<span class="sd">        :param decoder_dim: size of decoder&#39;s RNN</span>
<span class="sd">        :param attention_dim: size of the attention network</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Attention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_att</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoder_dim</span><span class="p">,</span> <span class="n">attention_dim</span><span class="p">)</span>  <span class="c1"># linear layer to transform encoded image</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_att</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">decoder_dim</span><span class="p">,</span> <span class="n">attention_dim</span><span class="p">)</span>  <span class="c1"># linear layer to transform decoder&#39;s output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">full_att</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">attention_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># linear layer to calculate values to be softmax-ed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># softmax layer to calculate weights</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_out</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward propagation.</span>
<span class="sd">        :param encoder_out: encoded images, a tensor of dimension (batch_size, num_pixels, encoder_dim)</span>
<span class="sd">        :param decoder_hidden: previous decoder output, a tensor of dimension (batch_size, decoder_dim)</span>
<span class="sd">        :return: attention weighted encoding, weights</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">pdb</span><span class="p">;</span><span class="n">pdb</span><span class="o">.</span><span class="n">set_trace</span><span class="p">()</span>
        <span class="n">att1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder_att</span><span class="p">(</span><span class="n">encoder_out</span><span class="p">)</span>  <span class="c1"># (batch_size, num_pixels, attention_dim)</span>
        <span class="n">att2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_att</span><span class="p">(</span><span class="n">decoder_hidden</span><span class="p">)</span>  <span class="c1"># (batch_size, attention_dim)</span>
        <span class="n">att</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_att</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">att1</span> <span class="o">+</span> <span class="n">att2</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># (batch_size, num_pixels)</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">att</span><span class="p">)</span>  <span class="c1"># (batch_size, num_pixels)</span>
        <span class="n">attention_weighted_encoding</span> <span class="o">=</span> <span class="p">(</span><span class="n">encoder_out</span> <span class="o">*</span> <span class="n">alpha</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (batch_size, encoder_dim)</span>

        <span class="k">return</span> <span class="n">attention_weighted_encoding</span><span class="p">,</span> <span class="n">alpha</span>


<span class="k">class</span> <span class="nc">DecoderWithAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Decoder.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attention_dim</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">decoder_dim</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">encoder_dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param attention_dim: size of attention network</span>
<span class="sd">        :param embed_dim: embedding size</span>
<span class="sd">        :param decoder_dim: size of decoder&#39;s RNN</span>
<span class="sd">        :param vocab_size: size of vocabulary</span>
<span class="sd">        :param encoder_dim: feature size of encoded images</span>
<span class="sd">        :param dropout: dropout</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DecoderWithAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_dim</span> <span class="o">=</span> <span class="n">encoder_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention_dim</span> <span class="o">=</span> <span class="n">attention_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span> <span class="o">=</span> <span class="n">embed_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_dim</span> <span class="o">=</span> <span class="n">decoder_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">(</span><span class="n">encoder_dim</span><span class="p">,</span> <span class="n">decoder_dim</span><span class="p">,</span> <span class="n">attention_dim</span><span class="p">)</span>  <span class="c1"># attention network</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">)</span>  <span class="c1"># embedding layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decode_step</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">embed_dim</span> <span class="o">+</span> <span class="n">encoder_dim</span><span class="p">,</span> <span class="n">decoder_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># decoding LSTMCell</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_h</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoder_dim</span><span class="p">,</span> <span class="n">decoder_dim</span><span class="p">)</span>  <span class="c1"># linear layer to find initial hidden state of LSTMCell</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_c</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoder_dim</span><span class="p">,</span> <span class="n">decoder_dim</span><span class="p">)</span>  <span class="c1"># linear layer to find initial cell state of LSTMCell</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f_beta</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">decoder_dim</span><span class="p">,</span> <span class="n">encoder_dim</span><span class="p">)</span>  <span class="c1"># linear layer to create a sigmoid-activated gate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">decoder_dim</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>  <span class="c1"># linear layer to find scores over vocabulary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>  <span class="c1"># initialize some layers with the uniform distribution</span>

    <span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes some parameters with values from the uniform distribution, for easier convergence.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">load_pretrained_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Loads embedding layer with pre-trained embeddings.</span>
<span class="sd">        :param embeddings: pre-trained embeddings</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">fine_tune_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fine_tune</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Allow fine-tuning of embedding layer? (Only makes sense to not-allow if using pre-trained embeddings).</span>
<span class="sd">        :param fine_tune: Allow?</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="n">fine_tune</span>

    <span class="k">def</span> <span class="nf">init_hidden_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_out</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates the initial hidden and cell states for the decoder&#39;s LSTM based on the encoded images.</span>
<span class="sd">        :param encoder_out: encoded images, a tensor of dimension (batch_size, num_pixels, encoder_dim)</span>
<span class="sd">        :return: hidden state, cell state</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mean_encoder_out</span> <span class="o">=</span> <span class="n">encoder_out</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_h</span><span class="p">(</span><span class="n">mean_encoder_out</span><span class="p">)</span>  <span class="c1"># (batch_size, decoder_dim)</span>
        <span class="n">c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_c</span><span class="p">(</span><span class="n">mean_encoder_out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">h</span><span class="p">,</span> <span class="n">c</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_out</span><span class="p">,</span> <span class="n">encoded_captions</span><span class="p">,</span> <span class="n">caption_lengths</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward propagation.</span>
<span class="sd">        :param encoder_out: encoded images, a tensor of dimension (batch_size, enc_image_size, enc_image_size, encoder_dim)</span>
<span class="sd">        :param encoded_captions: encoded captions, a tensor of dimension (batch_size, max_caption_length)</span>
<span class="sd">        :param caption_lengths: caption lengths, a tensor of dimension (batch_size, 1)</span>
<span class="sd">        :return: scores for vocabulary, sorted encoded captions, decode lengths, weights, sort indices</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">encoder_out</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">encoder_dim</span> <span class="o">=</span> <span class="n">encoder_out</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">vocab_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span>

        <span class="c1"># Flatten image</span>
        <span class="n">encoder_out</span> <span class="o">=</span> <span class="n">encoder_out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">encoder_dim</span><span class="p">)</span>  <span class="c1"># (batch_size, num_pixels, encoder_dim)</span>
        <span class="n">num_pixels</span> <span class="o">=</span> <span class="n">encoder_out</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Sort input data by decreasing lengths; why? apparent below</span>
        <span class="n">caption_lengths</span><span class="p">,</span> <span class="n">sort_ind</span> <span class="o">=</span> <span class="n">caption_lengths</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">encoder_out</span> <span class="o">=</span> <span class="n">encoder_out</span><span class="p">[</span><span class="n">sort_ind</span><span class="p">]</span>
        <span class="n">encoded_captions</span> <span class="o">=</span> <span class="n">encoded_captions</span><span class="p">[</span><span class="n">sort_ind</span><span class="p">]</span>

        <span class="c1"># Embedding</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">encoded_captions</span><span class="p">)</span>  <span class="c1"># (batch_size, max_caption_length, embed_dim)</span>

        <span class="c1"># Initialize LSTM state</span>
        <span class="n">h</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_hidden_state</span><span class="p">(</span><span class="n">encoder_out</span><span class="p">)</span>  <span class="c1"># (batch_size, decoder_dim)</span>

        <span class="c1"># We won&#39;t decode at the &lt;end&gt; position, since we&#39;ve finished generating as soon as we generate &lt;end&gt;</span>
        <span class="c1"># So, decoding lengths are actual lengths - 1</span>
        <span class="n">decode_lengths</span> <span class="o">=</span> <span class="p">(</span><span class="n">caption_lengths</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

        <span class="c1"># Create tensors to hold word predicion scores and alphas</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">decode_lengths</span><span class="p">),</span> <span class="n">vocab_size</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">alphas</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">decode_lengths</span><span class="p">),</span> <span class="n">num_pixels</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># At each time-step, decode by</span>
        <span class="c1"># attention-weighing the encoder&#39;s output based on the decoder&#39;s previous hidden state output</span>
        <span class="c1"># then generate a new word in the decoder with the previous word and the attention weighted encoding</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">decode_lengths</span><span class="p">)):</span>
            <span class="n">batch_size_t</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">l</span> <span class="o">&gt;</span> <span class="n">t</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">decode_lengths</span><span class="p">])</span>
            <span class="n">attention_weighted_encoding</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">encoder_out</span><span class="p">[:</span><span class="n">batch_size_t</span><span class="p">],</span>
                                                                <span class="n">h</span><span class="p">[:</span><span class="n">batch_size_t</span><span class="p">])</span>
<span class="c1">#             import pdb;pdb.set_trace()</span>
            <span class="n">gate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">f_beta</span><span class="p">(</span><span class="n">h</span><span class="p">[:</span><span class="n">batch_size_t</span><span class="p">]))</span>  <span class="c1"># gating scalar, (batch_size_t, encoder_dim)</span>
            <span class="n">attention_weighted_encoding</span> <span class="o">=</span> <span class="n">gate</span> <span class="o">*</span> <span class="n">attention_weighted_encoding</span>
            <span class="n">h</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode_step</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">embeddings</span><span class="p">[:</span><span class="n">batch_size_t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:],</span> <span class="n">attention_weighted_encoding</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                <span class="p">(</span><span class="n">h</span><span class="p">[:</span><span class="n">batch_size_t</span><span class="p">],</span> <span class="n">c</span><span class="p">[:</span><span class="n">batch_size_t</span><span class="p">]))</span>  <span class="c1"># (batch_size_t, decoder_dim)</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h</span><span class="p">))</span>  <span class="c1"># (batch_size_t, vocab_size)</span>
            <span class="n">predictions</span><span class="p">[:</span><span class="n">batch_size_t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">preds</span>
            <span class="n">alphas</span><span class="p">[:</span><span class="n">batch_size_t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">alpha</span>

        <span class="k">return</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">encoded_captions</span><span class="p">,</span> <span class="n">decode_lengths</span><span class="p">,</span> <span class="n">alphas</span><span class="p">,</span> <span class="n">sort_ind</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/vimarshc/anaconda3/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() &gt; 0
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">decoder</span> <span class="o">=</span> <span class="n">DecoderWithAttention</span><span class="p">(</span><span class="n">attention_dim</span><span class="o">=</span><span class="n">attention_dim</span><span class="p">,</span>
                               <span class="n">embed_dim</span><span class="o">=</span><span class="n">emb_dim</span><span class="p">,</span>
                               <span class="n">decoder_dim</span><span class="o">=</span><span class="n">decoder_dim</span><span class="p">,</span>
                               <span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">word_map</span><span class="p">),</span>
                               <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
<span class="n">decoder_optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="n">decoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">()),</span>
                                     <span class="n">lr</span><span class="o">=</span><span class="n">decoder_lr</span><span class="p">)</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">()</span>
<span class="n">encoder</span><span class="o">.</span><span class="n">fine_tune</span><span class="p">(</span><span class="n">fine_tune_encoder</span><span class="p">)</span>
<span class="n">encoder_optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="n">encoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">()),</span>
                                     <span class="n">lr</span><span class="o">=</span><span class="n">encoder_lr</span><span class="p">)</span> <span class="k">if</span> <span class="n">fine_tune_encoder</span> <span class="k">else</span> <span class="kc">None</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Custom dataloaders</span>
<span class="n">normalize</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span>
                                 <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">CaptionDataset</span><span class="p">(</span><span class="n">data_folder</span><span class="p">,</span> <span class="n">data_name</span><span class="p">,</span> <span class="s1">&#39;TRAIN&#39;</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">normalize</span><span class="p">])),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">CaptionDataset</span><span class="p">(</span><span class="n">data_folder</span><span class="p">,</span> <span class="n">data_name</span><span class="p">,</span> <span class="s1">&#39;VAL&#39;</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">normalize</span><span class="p">])),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Epochs</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># One epoch&#39;s training</span>
    <span class="n">train</span><span class="p">(</span><span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
          <span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">,</span>
          <span class="n">decoder</span><span class="o">=</span><span class="n">decoder</span><span class="p">,</span>
          <span class="n">criterion</span><span class="o">=</span><span class="n">criterion</span><span class="p">,</span>
          <span class="n">encoder_optimizer</span><span class="o">=</span><span class="n">encoder_optimizer</span><span class="p">,</span>
          <span class="n">decoder_optimizer</span><span class="o">=</span><span class="n">decoder_optimizer</span><span class="p">,</span>
          <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>&gt; <span class="ansi-green-fg">&lt;ipython-input-43-2d08ee031124&gt;</span>(35)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">     33 </span><span class="ansi-red-fg">        &#34;&#34;&#34;
</span><span class="ansi-green-fg">     34 </span><span class="ansi-red-fg">        </span><span class="ansi-green-fg">import</span> pdb<span class="ansi-blue-fg">;</span>pdb<span class="ansi-blue-fg">.</span>set_trace<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 35 </span><span class="ansi-red-fg">        </span>att1 <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>encoder_att<span class="ansi-blue-fg">(</span>encoder_out<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels, attention_dim)</span>
<span class="ansi-green-fg">     36 </span><span class="ansi-red-fg">        </span>att2 <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>decoder_att<span class="ansi-blue-fg">(</span>decoder_hidden<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, attention_dim)</span>
<span class="ansi-green-fg">     37 </span><span class="ansi-red-fg">        </span>att <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>full_att<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>relu<span class="ansi-blue-fg">(</span>att1 <span class="ansi-blue-fg">+</span> att2<span class="ansi-blue-fg">.</span>unsqueeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>squeeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels)</span>

ipdb&gt; p encoder_out.shape
torch.Size([4, 196, 2048])
ipdb&gt; n
&gt; <span class="ansi-green-fg">&lt;ipython-input-43-2d08ee031124&gt;</span>(36)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">     34 </span><span class="ansi-red-fg">        </span><span class="ansi-green-fg">import</span> pdb<span class="ansi-blue-fg">;</span>pdb<span class="ansi-blue-fg">.</span>set_trace<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">     35 </span><span class="ansi-red-fg">        </span>att1 <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>encoder_att<span class="ansi-blue-fg">(</span>encoder_out<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels, attention_dim)</span>
<span class="ansi-green-fg">---&gt; 36 </span><span class="ansi-red-fg">        </span>att2 <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>decoder_att<span class="ansi-blue-fg">(</span>decoder_hidden<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, attention_dim)</span>
<span class="ansi-green-fg">     37 </span><span class="ansi-red-fg">        </span>att <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>full_att<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>relu<span class="ansi-blue-fg">(</span>att1 <span class="ansi-blue-fg">+</span> att2<span class="ansi-blue-fg">.</span>unsqueeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>squeeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels)</span>
<span class="ansi-green-fg">     38 </span><span class="ansi-red-fg">        </span>alpha <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>softmax<span class="ansi-blue-fg">(</span>att<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels)</span>

ipdb&gt; p att1.shape
torch.Size([4, 196, 512])
ipdb&gt; n
&gt; <span class="ansi-green-fg">&lt;ipython-input-43-2d08ee031124&gt;</span>(37)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">     35 </span><span class="ansi-red-fg">        </span>att1 <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>encoder_att<span class="ansi-blue-fg">(</span>encoder_out<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels, attention_dim)</span>
<span class="ansi-green-fg">     36 </span><span class="ansi-red-fg">        </span>att2 <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>decoder_att<span class="ansi-blue-fg">(</span>decoder_hidden<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, attention_dim)</span>
<span class="ansi-green-fg">---&gt; 37 </span><span class="ansi-red-fg">        </span>att <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>full_att<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>relu<span class="ansi-blue-fg">(</span>att1 <span class="ansi-blue-fg">+</span> att2<span class="ansi-blue-fg">.</span>unsqueeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>squeeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels)</span>
<span class="ansi-green-fg">     38 </span><span class="ansi-red-fg">        </span>alpha <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>softmax<span class="ansi-blue-fg">(</span>att<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels)</span>
<span class="ansi-green-fg">     39 </span><span class="ansi-red-fg">        </span>attention_weighted_encoding <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">(</span>encoder_out <span class="ansi-blue-fg">*</span> alpha<span class="ansi-blue-fg">.</span>unsqueeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>sum<span class="ansi-blue-fg">(</span>dim<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, encoder_dim)</span>

ipdb&gt; p att2.shape
torch.Size([4, 512])
ipdb&gt; n
&gt; <span class="ansi-green-fg">&lt;ipython-input-43-2d08ee031124&gt;</span>(38)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">     36 </span><span class="ansi-red-fg">        </span>att2 <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>decoder_att<span class="ansi-blue-fg">(</span>decoder_hidden<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, attention_dim)</span>
<span class="ansi-green-fg">     37 </span><span class="ansi-red-fg">        </span>att <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>full_att<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>relu<span class="ansi-blue-fg">(</span>att1 <span class="ansi-blue-fg">+</span> att2<span class="ansi-blue-fg">.</span>unsqueeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>squeeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels)</span>
<span class="ansi-green-fg">---&gt; 38 </span><span class="ansi-red-fg">        </span>alpha <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>softmax<span class="ansi-blue-fg">(</span>att<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels)</span>
<span class="ansi-green-fg">     39 </span><span class="ansi-red-fg">        </span>attention_weighted_encoding <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">(</span>encoder_out <span class="ansi-blue-fg">*</span> alpha<span class="ansi-blue-fg">.</span>unsqueeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>sum<span class="ansi-blue-fg">(</span>dim<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, encoder_dim)</span>
<span class="ansi-green-fg">     40 </span>

ipdb&gt; p self.full_att
Linear(in_features=512, out_features=1, bias=True)
ipdb&gt; p (att1 + att2.unsqueeze(1)).shape
torch.Size([4, 196, 512])
ipdb&gt; n
&gt; <span class="ansi-green-fg">&lt;ipython-input-43-2d08ee031124&gt;</span>(39)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">     37 </span><span class="ansi-red-fg">        </span>att <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>full_att<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>relu<span class="ansi-blue-fg">(</span>att1 <span class="ansi-blue-fg">+</span> att2<span class="ansi-blue-fg">.</span>unsqueeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>squeeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels)</span>
<span class="ansi-green-fg">     38 </span><span class="ansi-red-fg">        </span>alpha <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>softmax<span class="ansi-blue-fg">(</span>att<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels)</span>
<span class="ansi-green-fg">---&gt; 39 </span><span class="ansi-red-fg">        </span>attention_weighted_encoding <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">(</span>encoder_out <span class="ansi-blue-fg">*</span> alpha<span class="ansi-blue-fg">.</span>unsqueeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>sum<span class="ansi-blue-fg">(</span>dim<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, encoder_dim)</span>
<span class="ansi-green-fg">     40 </span>
<span class="ansi-green-fg">     41 </span><span class="ansi-red-fg">        </span><span class="ansi-green-fg">return</span> attention_weighted_encoding<span class="ansi-blue-fg">,</span> alpha

ipdb&gt; p alpha.shape
torch.Size([4, 196])
ipdb&gt; p att.shape
torch.Size([4, 196])
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

