---

title: show_attend_and_tell


keywords: fastai
sidebar: home_sidebar



nb_path: "attention.show_attend_tell.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: attention.show_attend_tell.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># ! pip install pytorch</span>
<span class="c1"># ! pip install scipy==1.2.1</span>
<span class="c1"># ! pip install &#39;pillow&lt;7.0.0&#39;</span>
<span class="c1"># ! pip install torchvision</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span> rm flickr8k_op/* 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Loss function</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Custom dataloaders</span>
<span class="n">normalize</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span>
                                 <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">CaptionDataset</span><span class="p">(</span><span class="n">data_folder</span><span class="p">,</span> <span class="n">data_name</span><span class="p">,</span> <span class="s1">&#39;TRAIN&#39;</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">normalize</span><span class="p">])),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">CaptionDataset</span><span class="p">(</span><span class="n">data_folder</span><span class="p">,</span> <span class="n">data_name</span><span class="p">,</span> <span class="s1">&#39;VAL&#39;</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">normalize</span><span class="p">])),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">decoder</span> <span class="o">=</span> <span class="n">DecoderWithAttention</span><span class="p">(</span><span class="n">attention_dim</span><span class="o">=</span><span class="n">attention_dim</span><span class="p">,</span>
                               <span class="n">embed_dim</span><span class="o">=</span><span class="n">emb_dim</span><span class="p">,</span>
                               <span class="n">decoder_dim</span><span class="o">=</span><span class="n">decoder_dim</span><span class="p">,</span>
                               <span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">word_map</span><span class="p">),</span>
                               <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
<span class="n">decoder_optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="n">decoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">()),</span>
                                     <span class="n">lr</span><span class="o">=</span><span class="n">decoder_lr</span><span class="p">)</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">()</span>
<span class="n">encoder</span><span class="o">.</span><span class="n">fine_tune</span><span class="p">(</span><span class="n">fine_tune_encoder</span><span class="p">)</span>
<span class="n">encoder_optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">p</span><span class="p">:</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="n">encoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">()),</span>
                                     <span class="n">lr</span><span class="o">=</span><span class="n">encoder_lr</span><span class="p">)</span> <span class="k">if</span> <span class="n">fine_tune_encoder</span> <span class="k">else</span> <span class="kc">None</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">word_map_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_folder</span><span class="p">,</span> <span class="s1">&#39;WORDMAP_&#39;</span> <span class="o">+</span> <span class="n">data_name</span> <span class="o">+</span> <span class="s1">&#39;.json&#39;</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">word_map_file</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">j</span><span class="p">:</span>
    <span class="n">word_map</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">create_input_files</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="s1">&#39;flickr8k&#39;</span><span class="p">,</span>
                   <span class="n">karpathy_json_path</span><span class="o">=</span><span class="s1">&#39;dataset_flickr8k.json&#39;</span><span class="p">,</span>
                   <span class="n">image_folder</span><span class="o">=</span><span class="s1">&#39;/home/vimarshc/Documents/jupyterblog/flickr_data/Flickr_Data/Images/&#39;</span><span class="p">,</span>
                   <span class="n">captions_per_image</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                   <span class="n">min_word_freq</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                   <span class="n">output_folder</span><span class="o">=</span><span class="s1">&#39;flickr8k_op&#39;</span><span class="p">,</span>
                   <span class="n">max_len</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>  0%|          | 4/6000 [00:00&lt;02:43, 36.75it/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Reading TRAIN images and captions, storing to file...

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 6000/6000 [03:05&lt;00:00, 32.37it/s]
  0%|          | 4/1000 [00:00&lt;00:29, 34.23it/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Reading VAL images and captions, storing to file...

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 1000/1000 [00:28&lt;00:00, 34.50it/s]
  0%|          | 4/1000 [00:00&lt;00:27, 36.48it/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
Reading TEST images and captions, storing to file...

</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 1000/1000 [00:27&lt;00:00, 36.94it/s]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">encoder_optimizer</span><span class="p">,</span> <span class="n">decoder_optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs one epoch&#39;s training.</span>
<span class="sd">    :param train_loader: DataLoader for training data</span>
<span class="sd">    :param encoder: encoder model</span>
<span class="sd">    :param decoder: decoder model</span>
<span class="sd">    :param criterion: loss layer</span>
<span class="sd">    :param encoder_optimizer: optimizer to update encoder&#39;s weights (if fine-tuning)</span>
<span class="sd">    :param decoder_optimizer: optimizer to update decoder&#39;s weights</span>
<span class="sd">    :param epoch: epoch number</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">decoder</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>  <span class="c1"># train mode (dropout and batchnorm is used)</span>
    <span class="n">encoder</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="n">batch_time</span> <span class="o">=</span> <span class="n">AverageMeter</span><span class="p">()</span>  <span class="c1"># forward prop. + back prop. time</span>
    <span class="n">data_time</span> <span class="o">=</span> <span class="n">AverageMeter</span><span class="p">()</span>  <span class="c1"># data loading time</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="n">AverageMeter</span><span class="p">()</span>  <span class="c1"># loss (per word decoded)</span>
    <span class="n">top5accs</span> <span class="o">=</span> <span class="n">AverageMeter</span><span class="p">()</span>  <span class="c1"># top5 accuracy</span>

    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="c1"># Batches</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="n">caps</span><span class="p">,</span> <span class="n">caplens</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">data_time</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>
        <span class="c1"># Move to GPU, if available</span>
        <span class="n">imgs</span> <span class="o">=</span> <span class="n">imgs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">caps</span> <span class="o">=</span> <span class="n">caps</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">caplens</span> <span class="o">=</span> <span class="n">caplens</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Forward prop.</span>
        <span class="n">imgs</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>
        <span class="n">scores</span><span class="p">,</span> <span class="n">caps_sorted</span><span class="p">,</span> <span class="n">decode_lengths</span><span class="p">,</span> <span class="n">alphas</span><span class="p">,</span> <span class="n">sort_ind</span> <span class="o">=</span> <span class="n">decoder</span><span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="n">caps</span><span class="p">,</span> <span class="n">caplens</span><span class="p">)</span>

        <span class="c1"># Since we decoded starting with &lt;start&gt;, the targets are all words after &lt;start&gt;, up to &lt;end&gt;</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="n">caps_sorted</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>

        <span class="c1"># Remove timesteps that we didn&#39;t decode at, or are pads</span>
        <span class="c1"># pack_padded_sequence is an easy trick to do this</span>
        <span class="n">scores</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">pack_padded_sequence</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">decode_lengths</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">targets</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">pack_padded_sequence</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">decode_lengths</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Calculate loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>

        <span class="c1"># Add doubly stochastic attention regularization</span>
        <span class="n">loss</span> <span class="o">+=</span> <span class="n">alpha_c</span> <span class="o">*</span> <span class="p">((</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">alphas</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="c1"># Back prop.</span>
        <span class="n">decoder_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">encoder_optimizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">encoder_optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># Clip gradients</span>
        <span class="k">if</span> <span class="n">grad_clip</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">clip_gradient</span><span class="p">(</span><span class="n">decoder_optimizer</span><span class="p">,</span> <span class="n">grad_clip</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">encoder_optimizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">clip_gradient</span><span class="p">(</span><span class="n">encoder_optimizer</span><span class="p">,</span> <span class="n">grad_clip</span><span class="p">)</span>

        <span class="c1"># Update weights</span>
        <span class="n">decoder_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">encoder_optimizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">encoder_optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># Keep track of metrics</span>
        <span class="n">top5</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="n">losses</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="nb">sum</span><span class="p">(</span><span class="n">decode_lengths</span><span class="p">))</span>
        <span class="n">top5accs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">top5</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">decode_lengths</span><span class="p">))</span>
        <span class="n">batch_time</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>

        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        <span class="c1"># Print status</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">print_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch: [</span><span class="si">{0}</span><span class="s1">][</span><span class="si">{1}</span><span class="s1">/</span><span class="si">{2}</span><span class="s1">]</span><span class="se">\t</span><span class="s1">&#39;</span>
                  <span class="s1">&#39;Batch Time </span><span class="si">{batch_time.val:.3f}</span><span class="s1"> (</span><span class="si">{batch_time.avg:.3f}</span><span class="s1">)</span><span class="se">\t</span><span class="s1">&#39;</span>
                  <span class="s1">&#39;Data Load Time </span><span class="si">{data_time.val:.3f}</span><span class="s1"> (</span><span class="si">{data_time.avg:.3f}</span><span class="s1">)</span><span class="se">\t</span><span class="s1">&#39;</span>
                  <span class="s1">&#39;Loss </span><span class="si">{loss.val:.4f}</span><span class="s1"> (</span><span class="si">{loss.avg:.4f}</span><span class="s1">)</span><span class="se">\t</span><span class="s1">&#39;</span>
                  <span class="s1">&#39;Top-5 Accuracy </span><span class="si">{top5.val:.3f}</span><span class="s1"> (</span><span class="si">{top5.avg:.3f}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span>
                                                                          <span class="n">batch_time</span><span class="o">=</span><span class="n">batch_time</span><span class="p">,</span>
                                                                          <span class="n">data_time</span><span class="o">=</span><span class="n">data_time</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">losses</span><span class="p">,</span>
                                                                          <span class="n">top5</span><span class="o">=</span><span class="n">top5accs</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">h5py</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">transform</span><span class="p">,</span><span class="n">io</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">seed</span><span class="p">,</span> <span class="n">choice</span><span class="p">,</span> <span class="n">sample</span>


<span class="k">def</span> <span class="nf">create_input_files</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">karpathy_json_path</span><span class="p">,</span> <span class="n">image_folder</span><span class="p">,</span> <span class="n">captions_per_image</span><span class="p">,</span> <span class="n">min_word_freq</span><span class="p">,</span> <span class="n">output_folder</span><span class="p">,</span>
                       <span class="n">max_len</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates input files for training, validation, and test data.</span>
<span class="sd">    :param dataset: name of dataset, one of &#39;coco&#39;, &#39;flickr8k&#39;, &#39;flickr30k&#39;</span>
<span class="sd">    :param karpathy_json_path: path of Karpathy JSON file with splits and captions</span>
<span class="sd">    :param image_folder: folder with downloaded images</span>
<span class="sd">    :param captions_per_image: number of captions to sample per image</span>
<span class="sd">    :param min_word_freq: words occuring less frequently than this threshold are binned as &lt;unk&gt;s</span>
<span class="sd">    :param output_folder: folder to save files</span>
<span class="sd">    :param max_len: don&#39;t sample captions longer than this length</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">assert</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="p">{</span><span class="s1">&#39;coco&#39;</span><span class="p">,</span> <span class="s1">&#39;flickr8k&#39;</span><span class="p">,</span> <span class="s1">&#39;flickr30k&#39;</span><span class="p">}</span>
    

    <span class="c1"># Read Karpathy JSON</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">karpathy_json_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">j</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>

    <span class="c1"># Read image paths and captions for each image</span>
    <span class="n">train_image_paths</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">train_image_captions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">val_image_paths</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">val_image_captions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">test_image_paths</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">test_image_captions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">word_freq</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;images&#39;</span><span class="p">]:</span>
        <span class="n">captions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">img</span><span class="p">[</span><span class="s1">&#39;sentences&#39;</span><span class="p">]:</span>
            <span class="c1"># Update word frequency</span>
            <span class="n">word_freq</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="s1">&#39;tokens&#39;</span><span class="p">])</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="s1">&#39;tokens&#39;</span><span class="p">])</span> <span class="o">&lt;=</span> <span class="n">max_len</span><span class="p">:</span>
                <span class="n">captions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="s1">&#39;tokens&#39;</span><span class="p">])</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">captions</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">image_folder</span><span class="p">,</span> <span class="n">img</span><span class="p">[</span><span class="s1">&#39;filepath&#39;</span><span class="p">],</span> <span class="n">img</span><span class="p">[</span><span class="s1">&#39;filename&#39;</span><span class="p">])</span> <span class="k">if</span> <span class="n">dataset</span> <span class="o">==</span> <span class="s1">&#39;coco&#39;</span> <span class="k">else</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="n">image_folder</span><span class="p">,</span> <span class="n">img</span><span class="p">[</span><span class="s1">&#39;filename&#39;</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">img</span><span class="p">[</span><span class="s1">&#39;split&#39;</span><span class="p">]</span> <span class="ow">in</span> <span class="p">{</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;restval&#39;</span><span class="p">}:</span>
            <span class="n">train_image_paths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
            <span class="n">train_image_captions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">captions</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">img</span><span class="p">[</span><span class="s1">&#39;split&#39;</span><span class="p">]</span> <span class="ow">in</span> <span class="p">{</span><span class="s1">&#39;val&#39;</span><span class="p">}:</span>
            <span class="n">val_image_paths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
            <span class="n">val_image_captions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">captions</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">img</span><span class="p">[</span><span class="s1">&#39;split&#39;</span><span class="p">]</span> <span class="ow">in</span> <span class="p">{</span><span class="s1">&#39;test&#39;</span><span class="p">}:</span>
            <span class="n">test_image_paths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
            <span class="n">test_image_captions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">captions</span><span class="p">)</span>

            
    
    <span class="c1"># Sanity check</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_image_paths</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_image_captions</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_image_paths</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_image_captions</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_image_paths</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_image_captions</span><span class="p">)</span>
    

    <span class="c1"># Create word map</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">word_freq</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="n">word_freq</span><span class="p">[</span><span class="n">w</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">min_word_freq</span><span class="p">]</span>
    <span class="n">word_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">v</span><span class="p">,</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">words</span><span class="p">)}</span>
    <span class="n">word_map</span><span class="p">[</span><span class="s1">&#39;&lt;unk&gt;&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_map</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">word_map</span><span class="p">[</span><span class="s1">&#39;&lt;start&gt;&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_map</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">word_map</span><span class="p">[</span><span class="s1">&#39;&lt;end&gt;&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_map</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">word_map</span><span class="p">[</span><span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Create a base/root name for all output files</span>
    <span class="n">base_filename</span> <span class="o">=</span> <span class="n">dataset</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">captions_per_image</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;_cap_per_img_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">min_word_freq</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;_min_word_freq&#39;</span>

    <span class="c1"># Save word map to a JSON</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_folder</span><span class="p">,</span> <span class="s1">&#39;WORDMAP_&#39;</span> <span class="o">+</span> <span class="n">base_filename</span> <span class="o">+</span> <span class="s1">&#39;.json&#39;</span><span class="p">),</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">j</span><span class="p">:</span>
        <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">word_map</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>

    <span class="c1"># Sample captions for each image, save images to HDF5 file, and captions and their lengths to JSON files</span>
    <span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">impaths</span><span class="p">,</span> <span class="n">imcaps</span><span class="p">,</span> <span class="n">split</span> <span class="ow">in</span> <span class="p">[(</span><span class="n">train_image_paths</span><span class="p">,</span> <span class="n">train_image_captions</span><span class="p">,</span> <span class="s1">&#39;TRAIN&#39;</span><span class="p">),</span>
                                   <span class="p">(</span><span class="n">val_image_paths</span><span class="p">,</span> <span class="n">val_image_captions</span><span class="p">,</span> <span class="s1">&#39;VAL&#39;</span><span class="p">),</span>
                                   <span class="p">(</span><span class="n">test_image_paths</span><span class="p">,</span> <span class="n">test_image_captions</span><span class="p">,</span> <span class="s1">&#39;TEST&#39;</span><span class="p">)]:</span>

        <span class="k">with</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_folder</span><span class="p">,</span> <span class="n">split</span> <span class="o">+</span> <span class="s1">&#39;_IMAGES_&#39;</span> <span class="o">+</span> <span class="n">base_filename</span> <span class="o">+</span> <span class="s1">&#39;.hdf5&#39;</span><span class="p">),</span> <span class="s1">&#39;a&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">h</span><span class="p">:</span>
            <span class="c1"># Make a note of the number of captions we are sampling per image</span>
            <span class="n">h</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;captions_per_image&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">captions_per_image</span>

            <span class="c1"># Create dataset inside HDF5 file to store images</span>
            <span class="n">images</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">create_dataset</span><span class="p">(</span><span class="s1">&#39;images&#39;</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">impaths</span><span class="p">),</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;uint8&#39;</span><span class="p">)</span>

            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Reading </span><span class="si">%s</span><span class="s2"> images and captions, storing to file...</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">split</span><span class="p">)</span>

            <span class="n">enc_captions</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">caplens</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">path</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="n">impaths</span><span class="p">)):</span>

                <span class="c1"># Sample captions</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">imcaps</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">captions_per_image</span><span class="p">:</span>
                    <span class="n">captions</span> <span class="o">=</span> <span class="n">imcaps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">choice</span><span class="p">(</span><span class="n">imcaps</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">captions_per_image</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">imcaps</span><span class="p">[</span><span class="n">i</span><span class="p">]))]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">captions</span> <span class="o">=</span> <span class="n">sample</span><span class="p">(</span><span class="n">imcaps</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">k</span><span class="o">=</span><span class="n">captions_per_image</span><span class="p">)</span>

                <span class="c1"># Sanity check</span>
                <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">captions</span><span class="p">)</span> <span class="o">==</span> <span class="n">captions_per_image</span>

                <span class="c1"># Read images</span>
                <span class="n">img</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">impaths</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
                    <span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">img</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">img</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">img</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">))</span>
                <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="k">assert</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)</span>
                <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">255</span>

                <span class="c1"># Save image to HDF5 file</span>
                <span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">img</span>

                <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">captions</span><span class="p">):</span>
                    <span class="c1"># Encode captions</span>
                    <span class="n">enc_c</span> <span class="o">=</span> <span class="p">[</span><span class="n">word_map</span><span class="p">[</span><span class="s1">&#39;&lt;start&gt;&#39;</span><span class="p">]]</span> <span class="o">+</span> <span class="p">[</span><span class="n">word_map</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">word_map</span><span class="p">[</span><span class="s1">&#39;&lt;unk&gt;&#39;</span><span class="p">])</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">c</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
                        <span class="n">word_map</span><span class="p">[</span><span class="s1">&#39;&lt;end&gt;&#39;</span><span class="p">]]</span> <span class="o">+</span> <span class="p">[</span><span class="n">word_map</span><span class="p">[</span><span class="s1">&#39;&lt;pad&gt;&#39;</span><span class="p">]]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">))</span>

                    <span class="c1"># Find caption lengths</span>
                    <span class="n">c_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span>

                    <span class="n">enc_captions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">enc_c</span><span class="p">)</span>
                    <span class="n">caplens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">c_len</span><span class="p">)</span>

            <span class="c1"># Sanity check</span>
            <span class="k">assert</span> <span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">captions_per_image</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">enc_captions</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">caplens</span><span class="p">)</span>

            <span class="c1"># Save encoded captions and their lengths to JSON files</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_folder</span><span class="p">,</span> <span class="n">split</span> <span class="o">+</span> <span class="s1">&#39;_CAPTIONS_&#39;</span> <span class="o">+</span> <span class="n">base_filename</span> <span class="o">+</span> <span class="s1">&#39;.json&#39;</span><span class="p">),</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">j</span><span class="p">:</span>
                <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">enc_captions</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>

            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_folder</span><span class="p">,</span> <span class="n">split</span> <span class="o">+</span> <span class="s1">&#39;_CAPLENS_&#39;</span> <span class="o">+</span> <span class="n">base_filename</span> <span class="o">+</span> <span class="s1">&#39;.json&#39;</span><span class="p">),</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">j</span><span class="p">:</span>
                <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">caplens</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">init_embedding</span><span class="p">(</span><span class="n">embeddings</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fills embedding tensor with values from the uniform distribution.</span>
<span class="sd">    :param embeddings: embedding tensor</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">3.0</span> <span class="o">/</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="o">-</span><span class="n">bias</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">load_embeddings</span><span class="p">(</span><span class="n">emb_file</span><span class="p">,</span> <span class="n">word_map</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates an embedding tensor for the specified word map, for loading into the model.</span>
<span class="sd">    :param emb_file: file containing embeddings (stored in GloVe format)</span>
<span class="sd">    :param word_map: word map</span>
<span class="sd">    :return: embeddings in the same order as the words in the word map, dimension of embeddings</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Find embedding dimension</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">emb_file</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">emb_dim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">readline</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="n">vocab</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">word_map</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="c1"># Create tensor to hold embeddings, initialize</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">emb_dim</span><span class="p">)</span>
    <span class="n">init_embedding</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>

    <span class="c1"># Read embedding file</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Loading embeddings...&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="n">emb_file</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">):</span>
        <span class="n">line</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span>

        <span class="n">emb_word</span> <span class="o">=</span> <span class="n">line</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">embedding</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">n</span><span class="p">:</span> <span class="n">n</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">n</span><span class="o">.</span><span class="n">isspace</span><span class="p">(),</span> <span class="n">line</span><span class="p">[</span><span class="mi">1</span><span class="p">:])))</span>

        <span class="c1"># Ignore word if not in train_vocab</span>
        <span class="k">if</span> <span class="n">emb_word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="n">embeddings</span><span class="p">[</span><span class="n">word_map</span><span class="p">[</span><span class="n">emb_word</span><span class="p">]]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">embedding</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">emb_dim</span>


<span class="k">def</span> <span class="nf">clip_gradient</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">grad_clip</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Clips gradients computed during backpropagation to avoid explosion of gradients.</span>
<span class="sd">    :param optimizer: optimizer with the gradients to be clipped</span>
<span class="sd">    :param grad_clip: clip value</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">group</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clamp_</span><span class="p">(</span><span class="o">-</span><span class="n">grad_clip</span><span class="p">,</span> <span class="n">grad_clip</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">save_checkpoint</span><span class="p">(</span><span class="n">data_name</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">epochs_since_improvement</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">encoder_optimizer</span><span class="p">,</span> <span class="n">decoder_optimizer</span><span class="p">,</span>
                    <span class="n">bleu4</span><span class="p">,</span> <span class="n">is_best</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Saves model checkpoint.</span>
<span class="sd">    :param data_name: base name of processed dataset</span>
<span class="sd">    :param epoch: epoch number</span>
<span class="sd">    :param epochs_since_improvement: number of epochs since last improvement in BLEU-4 score</span>
<span class="sd">    :param encoder: encoder model</span>
<span class="sd">    :param decoder: decoder model</span>
<span class="sd">    :param encoder_optimizer: optimizer to update encoder&#39;s weights, if fine-tuning</span>
<span class="sd">    :param decoder_optimizer: optimizer to update decoder&#39;s weights</span>
<span class="sd">    :param bleu4: validation BLEU-4 score for this epoch</span>
<span class="sd">    :param is_best: is this checkpoint the best so far?</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">state</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
             <span class="s1">&#39;epochs_since_improvement&#39;</span><span class="p">:</span> <span class="n">epochs_since_improvement</span><span class="p">,</span>
             <span class="s1">&#39;bleu-4&#39;</span><span class="p">:</span> <span class="n">bleu4</span><span class="p">,</span>
             <span class="s1">&#39;encoder&#39;</span><span class="p">:</span> <span class="n">encoder</span><span class="p">,</span>
             <span class="s1">&#39;decoder&#39;</span><span class="p">:</span> <span class="n">decoder</span><span class="p">,</span>
             <span class="s1">&#39;encoder_optimizer&#39;</span><span class="p">:</span> <span class="n">encoder_optimizer</span><span class="p">,</span>
             <span class="s1">&#39;decoder_optimizer&#39;</span><span class="p">:</span> <span class="n">decoder_optimizer</span><span class="p">}</span>
    <span class="n">filename</span> <span class="o">=</span> <span class="s1">&#39;checkpoint_&#39;</span> <span class="o">+</span> <span class="n">data_name</span> <span class="o">+</span> <span class="s1">&#39;.pth.tar&#39;</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
    <span class="c1"># If this checkpoint is the best so far, store a copy so it doesn&#39;t get overwritten by a worse checkpoint</span>
    <span class="k">if</span> <span class="n">is_best</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="s1">&#39;BEST_&#39;</span> <span class="o">+</span> <span class="n">filename</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">AverageMeter</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Keeps track of most recent, average, sum, and count of a metric.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">avg</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val</span> <span class="o">=</span> <span class="n">val</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sum</span> <span class="o">+=</span> <span class="n">val</span> <span class="o">*</span> <span class="n">n</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">count</span> <span class="o">+=</span> <span class="n">n</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">avg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sum</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">count</span>


<span class="k">def</span> <span class="nf">adjust_learning_rate</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">shrink_factor</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Shrinks learning rate by a specified factor.</span>
<span class="sd">    :param optimizer: optimizer whose learning rate must be shrunk.</span>
<span class="sd">    :param shrink_factor: factor in interval (0, 1) to multiply learning rate with.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">DECAYING learning rate.&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">param_group</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">:</span>
        <span class="n">param_group</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">param_group</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">shrink_factor</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The new learning rate is </span><span class="si">%f</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">],))</span>


<span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes top-k accuracy, from predicted and true labels.</span>
<span class="sd">    :param scores: scores from the model</span>
<span class="sd">    :param targets: true labels</span>
<span class="sd">    :param k: k in top-k accuracy</span>
<span class="sd">    :return: top-k accuracy</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">ind</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="n">ind</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">ind</span><span class="p">))</span>
    <span class="n">correct_total</span> <span class="o">=</span> <span class="n">correct</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>  <span class="c1"># 0D tensor</span>
    <span class="k">return</span> <span class="n">correct_total</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="p">(</span><span class="mf">100.0</span> <span class="o">/</span> <span class="n">batch_size</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">torch.backends.cudnn</span> <span class="k">as</span> <span class="nn">cudnn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span>
<span class="kn">import</span> <span class="nn">torch.utils.data</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.nn.utils.rnn</span> <span class="kn">import</span> <span class="n">pack_padded_sequence</span>
<span class="kn">from</span> <span class="nn">nltk.translate.bleu_score</span> <span class="kn">import</span> <span class="n">corpus_bleu</span>

<span class="c1"># Data parameters</span>
<span class="n">data_folder</span> <span class="o">=</span> <span class="s1">&#39;flickr8k_op&#39;</span>  <span class="c1"># folder with data files saved by create_input_files.py</span>
<span class="n">data_name</span> <span class="o">=</span> <span class="s1">&#39;flickr8k_5_cap_per_img_5_min_word_freq&#39;</span>  <span class="c1"># base name shared by data files</span>

<span class="c1"># Model parameters</span>
<span class="n">emb_dim</span> <span class="o">=</span> <span class="mi">512</span>  <span class="c1"># dimension of word embeddings</span>
<span class="n">attention_dim</span> <span class="o">=</span> <span class="mi">512</span>  <span class="c1"># dimension of attention linear layers</span>
<span class="n">decoder_dim</span> <span class="o">=</span> <span class="mi">512</span>  <span class="c1"># dimension of decoder RNN</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>  <span class="c1"># sets device for model and PyTorch tensors</span>
<span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># set to true only if inputs to model are fixed size; otherwise lot of computational overhead</span>

<span class="c1"># Training parameters</span>
<span class="n">start_epoch</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">120</span>  <span class="c1"># number of epochs to train for (if early stopping is not triggered)</span>
<span class="n">epochs_since_improvement</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># keeps track of number of epochs since there&#39;s been an improvement in validation BLEU</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">workers</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># for data-loading; right now, only 1 works with h5py</span>
<span class="n">encoder_lr</span> <span class="o">=</span> <span class="mf">1e-4</span>  <span class="c1"># learning rate for encoder if fine-tuning</span>
<span class="n">decoder_lr</span> <span class="o">=</span> <span class="mf">4e-4</span>  <span class="c1"># learning rate for decoder</span>
<span class="n">grad_clip</span> <span class="o">=</span> <span class="mf">5.</span>  <span class="c1"># clip gradients at an absolute value of</span>
<span class="n">alpha_c</span> <span class="o">=</span> <span class="mf">1.</span>  <span class="c1"># regularization parameter for &#39;doubly stochastic attention&#39;, as in the paper</span>
<span class="n">best_bleu4</span> <span class="o">=</span> <span class="mf">0.</span>  <span class="c1"># BLEU-4 score right now</span>
<span class="n">print_freq</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># print training/validation stats every __ batches</span>
<span class="n">fine_tune_encoder</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># fine-tune encoder?</span>
<span class="n">checkpoint</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># path to checkpoint, None if none</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">torch.backends.cudnn</span> <span class="k">as</span> <span class="nn">cudnn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span>
<span class="kn">import</span> <span class="nn">torch.utils.data</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.nn.utils.rnn</span> <span class="kn">import</span> <span class="n">pack_padded_sequence</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">import</span> <span class="nn">h5py</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="k">class</span> <span class="nc">CaptionDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A PyTorch Dataset class to be used in a PyTorch DataLoader to create batches.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_folder</span><span class="p">,</span> <span class="n">data_name</span><span class="p">,</span> <span class="n">split</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param data_folder: folder where data files are stored</span>
<span class="sd">        :param data_name: base name of processed datasets</span>
<span class="sd">        :param split: split, one of &#39;TRAIN&#39;, &#39;VAL&#39;, or &#39;TEST&#39;</span>
<span class="sd">        :param transform: image transform pipeline</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="o">=</span> <span class="n">split</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="ow">in</span> <span class="p">{</span><span class="s1">&#39;TRAIN&#39;</span><span class="p">,</span> <span class="s1">&#39;VAL&#39;</span><span class="p">,</span> <span class="s1">&#39;TEST&#39;</span><span class="p">}</span>

        <span class="c1"># Open hdf5 file where images are stored</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_folder</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="o">+</span> <span class="s1">&#39;_IMAGES_&#39;</span> <span class="o">+</span> <span class="n">data_name</span> <span class="o">+</span> <span class="s1">&#39;.hdf5&#39;</span><span class="p">),</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">imgs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">[</span><span class="s1">&#39;images&#39;</span><span class="p">]</span>

        <span class="c1"># Captions per image</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cpi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;captions_per_image&#39;</span><span class="p">]</span>

        <span class="c1"># Load encoded captions (completely into memory)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_folder</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="o">+</span> <span class="s1">&#39;_CAPTIONS_&#39;</span> <span class="o">+</span> <span class="n">data_name</span> <span class="o">+</span> <span class="s1">&#39;.json&#39;</span><span class="p">),</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">j</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">captions</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>

        <span class="c1"># Load caption lengths (completely into memory)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_folder</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="o">+</span> <span class="s1">&#39;_CAPLENS_&#39;</span> <span class="o">+</span> <span class="n">data_name</span> <span class="o">+</span> <span class="s1">&#39;.json&#39;</span><span class="p">),</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">j</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">caplens</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>

        <span class="c1"># PyTorch transformation pipeline for the image (normalizing, etc.)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>

        <span class="c1"># Total number of datapoints</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">captions</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="c1"># Remember, the Nth caption corresponds to the (N // captions_per_image)th image</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">imgs</span><span class="p">[</span><span class="n">i</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpi</span><span class="p">]</span> <span class="o">/</span> <span class="mf">255.</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

        <span class="n">caption</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">captions</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

        <span class="n">caplen</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">caplens</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="ow">is</span> <span class="s1">&#39;TRAIN&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">img</span><span class="p">,</span> <span class="n">caption</span><span class="p">,</span> <span class="n">caplen</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># For validation of testing, also return all &#39;captions_per_image&#39; captions to find BLEU-4 score</span>
            <span class="n">all_captions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">captions</span><span class="p">[((</span><span class="n">i</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpi</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpi</span><span class="p">):(((</span><span class="n">i</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpi</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpi</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpi</span><span class="p">)])</span>
            <span class="k">return</span> <span class="n">img</span><span class="p">,</span> <span class="n">caption</span><span class="p">,</span> <span class="n">caplen</span><span class="p">,</span> <span class="n">all_captions</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_size</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Encoder.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoded_image_size</span><span class="o">=</span><span class="mi">14</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc_image_size</span> <span class="o">=</span> <span class="n">encoded_image_size</span>

        <span class="n">resnet</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">resnet101</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># pretrained ImageNet ResNet-101</span>

        <span class="c1"># Remove linear and pool layers (since we&#39;re not doing classification)</span>
        <span class="n">modules</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">resnet</span><span class="o">.</span><span class="n">children</span><span class="p">())[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resnet</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">modules</span><span class="p">)</span>

        <span class="c1"># Resize image to fixed size to allow input images of variable size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">adaptive_pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="n">encoded_image_size</span><span class="p">,</span> <span class="n">encoded_image_size</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">fine_tune</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward propagation.</span>
<span class="sd">        :param images: images, a tensor of dimensions (batch_size, 3, image_size, image_size)</span>
<span class="sd">        :return: encoded images</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">pdb</span><span class="p">;</span><span class="n">pdb</span><span class="o">.</span><span class="n">set_trace</span><span class="p">()</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">resnet</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>  <span class="c1"># (batch_size, 2048, image_size/32, image_size/32)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">adaptive_pool</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>  <span class="c1"># (batch_size, 2048, encoded_image_size, encoded_image_size)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># (batch_size, encoded_image_size, encoded_image_size, 2048)</span>
        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span> <span class="nf">fine_tune</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fine_tune</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Allow or prevent the computation of gradients for convolutional blocks 2 through 4 of the encoder.</span>
<span class="sd">        :param fine_tune: Allow?</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">resnet</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="c1"># If fine-tuning, only fine-tune convolutional blocks 2 through 4</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">resnet</span><span class="o">.</span><span class="n">children</span><span class="p">())[</span><span class="mi">5</span><span class="p">:]:</span>
            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">c</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="n">fine_tune</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torchvision</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>



<span class="k">class</span> <span class="nc">Attention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Attention Network.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_dim</span><span class="p">,</span> <span class="n">decoder_dim</span><span class="p">,</span> <span class="n">attention_dim</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param encoder_dim: feature size of encoded images</span>
<span class="sd">        :param decoder_dim: size of decoder&#39;s RNN</span>
<span class="sd">        :param attention_dim: size of the attention network</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Attention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_att</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoder_dim</span><span class="p">,</span> <span class="n">attention_dim</span><span class="p">)</span>  <span class="c1"># linear layer to transform encoded image</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_att</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">decoder_dim</span><span class="p">,</span> <span class="n">attention_dim</span><span class="p">)</span>  <span class="c1"># linear layer to transform decoder&#39;s output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">full_att</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">attention_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># linear layer to calculate values to be softmax-ed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># softmax layer to calculate weights</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_out</span><span class="p">,</span> <span class="n">decoder_hidden</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward propagation.</span>
<span class="sd">        :param encoder_out: encoded images, a tensor of dimension (batch_size, num_pixels, encoder_dim)</span>
<span class="sd">        :param decoder_hidden: previous decoder output, a tensor of dimension (batch_size, decoder_dim)</span>
<span class="sd">        :return: attention weighted encoding, weights</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">pdb</span><span class="p">;</span><span class="n">pdb</span><span class="o">.</span><span class="n">set_trace</span><span class="p">()</span>
        <span class="n">att1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder_att</span><span class="p">(</span><span class="n">encoder_out</span><span class="p">)</span>  <span class="c1"># (batch_size, num_pixels, attention_dim)</span>
        <span class="n">att2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_att</span><span class="p">(</span><span class="n">decoder_hidden</span><span class="p">)</span>  <span class="c1"># (batch_size, attention_dim)</span>
        <span class="n">att</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">full_att</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">att1</span> <span class="o">+</span> <span class="n">att2</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># (batch_size, num_pixels)</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">att</span><span class="p">)</span>  <span class="c1"># (batch_size, num_pixels)</span>
        <span class="n">attention_weighted_encoding</span> <span class="o">=</span> <span class="p">(</span><span class="n">encoder_out</span> <span class="o">*</span> <span class="n">alpha</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (batch_size, encoder_dim)</span>

        <span class="k">return</span> <span class="n">attention_weighted_encoding</span><span class="p">,</span> <span class="n">alpha</span>


<span class="k">class</span> <span class="nc">DecoderWithAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Decoder.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attention_dim</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">,</span> <span class="n">decoder_dim</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">encoder_dim</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param attention_dim: size of attention network</span>
<span class="sd">        :param embed_dim: embedding size</span>
<span class="sd">        :param decoder_dim: size of decoder&#39;s RNN</span>
<span class="sd">        :param vocab_size: size of vocabulary</span>
<span class="sd">        :param encoder_dim: feature size of encoded images</span>
<span class="sd">        :param dropout: dropout</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DecoderWithAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_dim</span> <span class="o">=</span> <span class="n">encoder_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention_dim</span> <span class="o">=</span> <span class="n">attention_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed_dim</span> <span class="o">=</span> <span class="n">embed_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_dim</span> <span class="o">=</span> <span class="n">decoder_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">Attention</span><span class="p">(</span><span class="n">encoder_dim</span><span class="p">,</span> <span class="n">decoder_dim</span><span class="p">,</span> <span class="n">attention_dim</span><span class="p">)</span>  <span class="c1"># attention network</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">)</span>  <span class="c1"># embedding layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decode_step</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">embed_dim</span> <span class="o">+</span> <span class="n">encoder_dim</span><span class="p">,</span> <span class="n">decoder_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># decoding LSTMCell</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_h</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoder_dim</span><span class="p">,</span> <span class="n">decoder_dim</span><span class="p">)</span>  <span class="c1"># linear layer to find initial hidden state of LSTMCell</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_c</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoder_dim</span><span class="p">,</span> <span class="n">decoder_dim</span><span class="p">)</span>  <span class="c1"># linear layer to find initial cell state of LSTMCell</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">f_beta</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">decoder_dim</span><span class="p">,</span> <span class="n">encoder_dim</span><span class="p">)</span>  <span class="c1"># linear layer to create a sigmoid-activated gate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">decoder_dim</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>  <span class="c1"># linear layer to find scores over vocabulary</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>  <span class="c1"># initialize some layers with the uniform distribution</span>

    <span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes some parameters with values from the uniform distribution, for easier convergence.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">load_pretrained_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Loads embedding layer with pre-trained embeddings.</span>
<span class="sd">        :param embeddings: pre-trained embeddings</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">fine_tune_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fine_tune</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Allow fine-tuning of embedding layer? (Only makes sense to not-allow if using pre-trained embeddings).</span>
<span class="sd">        :param fine_tune: Allow?</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="n">fine_tune</span>

    <span class="k">def</span> <span class="nf">init_hidden_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_out</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates the initial hidden and cell states for the decoder&#39;s LSTM based on the encoded images.</span>
<span class="sd">        :param encoder_out: encoded images, a tensor of dimension (batch_size, num_pixels, encoder_dim)</span>
<span class="sd">        :return: hidden state, cell state</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mean_encoder_out</span> <span class="o">=</span> <span class="n">encoder_out</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_h</span><span class="p">(</span><span class="n">mean_encoder_out</span><span class="p">)</span>  <span class="c1"># (batch_size, decoder_dim)</span>
        <span class="n">c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_c</span><span class="p">(</span><span class="n">mean_encoder_out</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">h</span><span class="p">,</span> <span class="n">c</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_out</span><span class="p">,</span> <span class="n">encoded_captions</span><span class="p">,</span> <span class="n">caption_lengths</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward propagation.</span>
<span class="sd">        :param encoder_out: encoded images, a tensor of dimension (batch_size, enc_image_size, enc_image_size, encoder_dim)</span>
<span class="sd">        :param encoded_captions: encoded captions, a tensor of dimension (batch_size, max_caption_length)</span>
<span class="sd">        :param caption_lengths: caption lengths, a tensor of dimension (batch_size, 1)</span>
<span class="sd">        :return: scores for vocabulary, sorted encoded captions, decode lengths, weights, sort indices</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">import</span> <span class="nn">pdb</span><span class="p">;</span><span class="n">pdb</span><span class="o">.</span><span class="n">set_trace</span><span class="p">()</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">encoder_out</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">encoder_dim</span> <span class="o">=</span> <span class="n">encoder_out</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">vocab_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span>

        <span class="c1"># Flatten image</span>
        <span class="n">encoder_out</span> <span class="o">=</span> <span class="n">encoder_out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">encoder_dim</span><span class="p">)</span>  <span class="c1"># (batch_size, num_pixels, encoder_dim)</span>
        <span class="n">num_pixels</span> <span class="o">=</span> <span class="n">encoder_out</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Sort input data by decreasing lengths; why? apparent below</span>
        <span class="n">caption_lengths</span><span class="p">,</span> <span class="n">sort_ind</span> <span class="o">=</span> <span class="n">caption_lengths</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">encoder_out</span> <span class="o">=</span> <span class="n">encoder_out</span><span class="p">[</span><span class="n">sort_ind</span><span class="p">]</span>
        <span class="n">encoded_captions</span> <span class="o">=</span> <span class="n">encoded_captions</span><span class="p">[</span><span class="n">sort_ind</span><span class="p">]</span>

        <span class="c1"># Embedding</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">encoded_captions</span><span class="p">)</span>  <span class="c1"># (batch_size, max_caption_length, embed_dim)</span>

        <span class="c1"># Initialize LSTM state</span>
        <span class="n">h</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_hidden_state</span><span class="p">(</span><span class="n">encoder_out</span><span class="p">)</span>  <span class="c1"># (batch_size, decoder_dim)</span>

        <span class="c1"># We won&#39;t decode at the &lt;end&gt; position, since we&#39;ve finished generating as soon as we generate &lt;end&gt;</span>
        <span class="c1"># So, decoding lengths are actual lengths - 1</span>
        <span class="n">decode_lengths</span> <span class="o">=</span> <span class="p">(</span><span class="n">caption_lengths</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

        <span class="c1"># Create tensors to hold word predicion scores and alphas</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">decode_lengths</span><span class="p">),</span> <span class="n">vocab_size</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">alphas</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">decode_lengths</span><span class="p">),</span> <span class="n">num_pixels</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># At each time-step, decode by</span>
        <span class="c1"># attention-weighing the encoder&#39;s output based on the decoder&#39;s previous hidden state output</span>
        <span class="c1"># then generate a new word in the decoder with the previous word and the attention weighted encoding</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">decode_lengths</span><span class="p">)):</span>
            <span class="n">batch_size_t</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">l</span> <span class="o">&gt;</span> <span class="n">t</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">decode_lengths</span><span class="p">])</span>
            <span class="n">attention_weighted_encoding</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">encoder_out</span><span class="p">[:</span><span class="n">batch_size_t</span><span class="p">],</span>
                                                                <span class="n">h</span><span class="p">[:</span><span class="n">batch_size_t</span><span class="p">])</span>
            <span class="n">gate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">f_beta</span><span class="p">(</span><span class="n">h</span><span class="p">[:</span><span class="n">batch_size_t</span><span class="p">]))</span>  <span class="c1"># gating scalar, (batch_size_t, encoder_dim)</span>
            <span class="n">attention_weighted_encoding</span> <span class="o">=</span> <span class="n">gate</span> <span class="o">*</span> <span class="n">attention_weighted_encoding</span>
            <span class="n">h</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode_step</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">embeddings</span><span class="p">[:</span><span class="n">batch_size_t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:],</span> <span class="n">attention_weighted_encoding</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                <span class="p">(</span><span class="n">h</span><span class="p">[:</span><span class="n">batch_size_t</span><span class="p">],</span> <span class="n">c</span><span class="p">[:</span><span class="n">batch_size_t</span><span class="p">]))</span>  <span class="c1"># (batch_size_t, decoder_dim)</span>
            <span class="n">preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">h</span><span class="p">))</span>  <span class="c1"># (batch_size_t, vocab_size)</span>
            <span class="n">predictions</span><span class="p">[:</span><span class="n">batch_size_t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">preds</span>
            <span class="n">alphas</span><span class="p">[:</span><span class="n">batch_size_t</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">alpha</span>

        <span class="k">return</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">encoded_captions</span><span class="p">,</span> <span class="n">decode_lengths</span><span class="p">,</span> <span class="n">alphas</span><span class="p">,</span> <span class="n">sort_ind</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Custom dataloaders</span>
<span class="n">normalize</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span>
                                 <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">CaptionDataset</span><span class="p">(</span><span class="n">data_folder</span><span class="p">,</span> <span class="n">data_name</span><span class="p">,</span> <span class="s1">&#39;TRAIN&#39;</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">normalize</span><span class="p">])),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">CaptionDataset</span><span class="p">(</span><span class="n">data_folder</span><span class="p">,</span> <span class="n">data_name</span><span class="p">,</span> <span class="s1">&#39;VAL&#39;</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">normalize</span><span class="p">])),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Epochs</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
    <span class="c1"># One epoch&#39;s training</span>
    <span class="n">train</span><span class="p">(</span><span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
          <span class="n">encoder</span><span class="o">=</span><span class="n">encoder</span><span class="p">,</span>
          <span class="n">decoder</span><span class="o">=</span><span class="n">decoder</span><span class="p">,</span>
          <span class="n">criterion</span><span class="o">=</span><span class="n">criterion</span><span class="p">,</span>
          <span class="n">encoder_optimizer</span><span class="o">=</span><span class="n">encoder_optimizer</span><span class="p">,</span>
          <span class="n">decoder_optimizer</span><span class="o">=</span><span class="n">decoder_optimizer</span><span class="p">,</span>
          <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>&gt; <span class="ansi-green-fg">&lt;ipython-input-7-3cbbf1757317&gt;</span>(27)<span class="ansi-cyan-fg">train</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">     25 </span><span class="ansi-red-fg">        </span><span class="ansi-green-fg">import</span> pdb<span class="ansi-blue-fg">;</span>pdb<span class="ansi-blue-fg">.</span>set_trace<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">     26 </span><span class="ansi-red-fg">        </span><span class="ansi-red-fg"># Move to GPU, if available</span>
<span class="ansi-green-fg">---&gt; 27 </span><span class="ansi-red-fg">        </span>imgs <span class="ansi-blue-fg">=</span> imgs<span class="ansi-blue-fg">.</span>to<span class="ansi-blue-fg">(</span>device<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">     28 </span><span class="ansi-red-fg">        </span>caps <span class="ansi-blue-fg">=</span> caps<span class="ansi-blue-fg">.</span>to<span class="ansi-blue-fg">(</span>device<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">     29 </span><span class="ansi-red-fg">        </span>caplens <span class="ansi-blue-fg">=</span> caplens<span class="ansi-blue-fg">.</span>to<span class="ansi-blue-fg">(</span>device<span class="ansi-blue-fg">)</span>

ipdb&gt; c
&gt; <span class="ansi-green-fg">&lt;ipython-input-2-e4369de1a3d5&gt;</span>(28)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">     26 </span><span class="ansi-red-fg">        &#34;&#34;&#34;
</span><span class="ansi-green-fg">     27 </span><span class="ansi-red-fg">        </span><span class="ansi-green-fg">import</span> pdb<span class="ansi-blue-fg">;</span>pdb<span class="ansi-blue-fg">.</span>set_trace<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 28 </span><span class="ansi-red-fg">        </span>out <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>resnet<span class="ansi-blue-fg">(</span>images<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, 2048, image_size/32, image_size/32)</span>
<span class="ansi-green-fg">     29 </span><span class="ansi-red-fg">        </span>out <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>adaptive_pool<span class="ansi-blue-fg">(</span>out<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, 2048, encoded_image_size, encoded_image_size)</span>
<span class="ansi-green-fg">     30 </span><span class="ansi-red-fg">        </span>out <span class="ansi-blue-fg">=</span> out<span class="ansi-blue-fg">.</span>permute<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">3</span><span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, encoded_image_size, encoded_image_size, 2048)</span>

ipdb&gt; c
&gt; <span class="ansi-green-fg">&lt;ipython-input-1-ffe59a3ddac7&gt;</span>(122)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">    120 </span><span class="ansi-red-fg">        &#34;&#34;&#34;
</span><span class="ansi-green-fg">    121 </span><span class="ansi-red-fg">        </span><span class="ansi-green-fg">import</span> pdb<span class="ansi-blue-fg">;</span>pdb<span class="ansi-blue-fg">.</span>set_trace<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 122 </span><span class="ansi-red-fg">        </span>batch_size <span class="ansi-blue-fg">=</span> encoder_out<span class="ansi-blue-fg">.</span>size<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">    123 </span><span class="ansi-red-fg">        </span>encoder_dim <span class="ansi-blue-fg">=</span> encoder_out<span class="ansi-blue-fg">.</span>size<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">-</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">    124 </span><span class="ansi-red-fg">        </span>vocab_size <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>vocab_size

ipdb&gt; n
&gt; <span class="ansi-green-fg">&lt;ipython-input-1-ffe59a3ddac7&gt;</span>(123)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">    121 </span><span class="ansi-red-fg">        </span><span class="ansi-green-fg">import</span> pdb<span class="ansi-blue-fg">;</span>pdb<span class="ansi-blue-fg">.</span>set_trace<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">    122 </span><span class="ansi-red-fg">        </span>batch_size <span class="ansi-blue-fg">=</span> encoder_out<span class="ansi-blue-fg">.</span>size<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 123 </span><span class="ansi-red-fg">        </span>encoder_dim <span class="ansi-blue-fg">=</span> encoder_out<span class="ansi-blue-fg">.</span>size<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">-</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">    124 </span><span class="ansi-red-fg">        </span>vocab_size <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>vocab_size
<span class="ansi-green-fg">    125 </span>

ipdb&gt; n
&gt; <span class="ansi-green-fg">&lt;ipython-input-1-ffe59a3ddac7&gt;</span>(124)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">    122 </span><span class="ansi-red-fg">        </span>batch_size <span class="ansi-blue-fg">=</span> encoder_out<span class="ansi-blue-fg">.</span>size<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">    123 </span><span class="ansi-red-fg">        </span>encoder_dim <span class="ansi-blue-fg">=</span> encoder_out<span class="ansi-blue-fg">.</span>size<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">-</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 124 </span><span class="ansi-red-fg">        </span>vocab_size <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>vocab_size
<span class="ansi-green-fg">    125 </span>
<span class="ansi-green-fg">    126 </span><span class="ansi-red-fg">        </span><span class="ansi-red-fg"># Flatten image</span>

ipdb&gt; n
&gt; <span class="ansi-green-fg">&lt;ipython-input-1-ffe59a3ddac7&gt;</span>(127)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">    125 </span>
<span class="ansi-green-fg">    126 </span><span class="ansi-red-fg">        </span><span class="ansi-red-fg"># Flatten image</span>
<span class="ansi-green-fg">--&gt; 127 </span><span class="ansi-red-fg">        </span>encoder_out <span class="ansi-blue-fg">=</span> encoder_out<span class="ansi-blue-fg">.</span>view<span class="ansi-blue-fg">(</span>batch_size<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">-</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">,</span> encoder_dim<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels, encoder_dim)</span>
<span class="ansi-green-fg">    128 </span><span class="ansi-red-fg">        </span>num_pixels <span class="ansi-blue-fg">=</span> encoder_out<span class="ansi-blue-fg">.</span>size<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">    129 </span>

ipdb&gt; n
&gt; <span class="ansi-green-fg">&lt;ipython-input-1-ffe59a3ddac7&gt;</span>(128)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">    126 </span><span class="ansi-red-fg">        </span><span class="ansi-red-fg"># Flatten image</span>
<span class="ansi-green-fg">    127 </span><span class="ansi-red-fg">        </span>encoder_out <span class="ansi-blue-fg">=</span> encoder_out<span class="ansi-blue-fg">.</span>view<span class="ansi-blue-fg">(</span>batch_size<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">-</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">,</span> encoder_dim<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels, encoder_dim)</span>
<span class="ansi-green-fg">--&gt; 128 </span><span class="ansi-red-fg">        </span>num_pixels <span class="ansi-blue-fg">=</span> encoder_out<span class="ansi-blue-fg">.</span>size<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">    129 </span>
<span class="ansi-green-fg">    130 </span><span class="ansi-red-fg">        </span><span class="ansi-red-fg"># Sort input data by decreasing lengths; why? apparent below</span>

ipdb&gt; p encoder_out.shape
torch.Size([4, 196, 2048])
ipdb&gt; n
&gt; <span class="ansi-green-fg">&lt;ipython-input-1-ffe59a3ddac7&gt;</span>(131)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">    129 </span>
<span class="ansi-green-fg">    130 </span><span class="ansi-red-fg">        </span><span class="ansi-red-fg"># Sort input data by decreasing lengths; why? apparent below</span>
<span class="ansi-green-fg">--&gt; 131 </span><span class="ansi-red-fg">        </span>caption_lengths<span class="ansi-blue-fg">,</span> sort_ind <span class="ansi-blue-fg">=</span> caption_lengths<span class="ansi-blue-fg">.</span>squeeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>sort<span class="ansi-blue-fg">(</span>dim<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">,</span> descending<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">    132 </span><span class="ansi-red-fg">        </span>encoder_out <span class="ansi-blue-fg">=</span> encoder_out<span class="ansi-blue-fg">[</span>sort_ind<span class="ansi-blue-fg">]</span>
<span class="ansi-green-fg">    133 </span><span class="ansi-red-fg">        </span>encoded_captions <span class="ansi-blue-fg">=</span> encoded_captions<span class="ansi-blue-fg">[</span>sort_ind<span class="ansi-blue-fg">]</span>

ipdb&gt; p num_pixels 
196
ipdb&gt; caption_lengths
tensor([[ 7],
        [11],
        [ 9],
        [16]])
ipdb&gt; p caption_lengths.squeeze(1)
tensor([ 7, 11,  9, 16])
ipdb&gt; caption_lengths.squeeze(1).sort(dim=0, descending=True)
torch.return_types.sort(
values=tensor([16, 11,  9,  7]),
indices=tensor([3, 1, 2, 0]))
ipdb&gt; n
&gt; <span class="ansi-green-fg">&lt;ipython-input-1-ffe59a3ddac7&gt;</span>(132)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">    130 </span><span class="ansi-red-fg">        </span><span class="ansi-red-fg"># Sort input data by decreasing lengths; why? apparent below</span>
<span class="ansi-green-fg">    131 </span><span class="ansi-red-fg">        </span>caption_lengths<span class="ansi-blue-fg">,</span> sort_ind <span class="ansi-blue-fg">=</span> caption_lengths<span class="ansi-blue-fg">.</span>squeeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>sort<span class="ansi-blue-fg">(</span>dim<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">,</span> descending<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 132 </span><span class="ansi-red-fg">        </span>encoder_out <span class="ansi-blue-fg">=</span> encoder_out<span class="ansi-blue-fg">[</span>sort_ind<span class="ansi-blue-fg">]</span>
<span class="ansi-green-fg">    133 </span><span class="ansi-red-fg">        </span>encoded_captions <span class="ansi-blue-fg">=</span> encoded_captions<span class="ansi-blue-fg">[</span>sort_ind<span class="ansi-blue-fg">]</span>
<span class="ansi-green-fg">    134 </span>

ipdb&gt; n
&gt; <span class="ansi-green-fg">&lt;ipython-input-1-ffe59a3ddac7&gt;</span>(133)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">    131 </span><span class="ansi-red-fg">        </span>caption_lengths<span class="ansi-blue-fg">,</span> sort_ind <span class="ansi-blue-fg">=</span> caption_lengths<span class="ansi-blue-fg">.</span>squeeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>sort<span class="ansi-blue-fg">(</span>dim<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">,</span> descending<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">    132 </span><span class="ansi-red-fg">        </span>encoder_out <span class="ansi-blue-fg">=</span> encoder_out<span class="ansi-blue-fg">[</span>sort_ind<span class="ansi-blue-fg">]</span>
<span class="ansi-green-fg">--&gt; 133 </span><span class="ansi-red-fg">        </span>encoded_captions <span class="ansi-blue-fg">=</span> encoded_captions<span class="ansi-blue-fg">[</span>sort_ind<span class="ansi-blue-fg">]</span>
<span class="ansi-green-fg">    134 </span>
<span class="ansi-green-fg">    135 </span><span class="ansi-red-fg">        </span><span class="ansi-red-fg"># Embedding</span>

ipdb&gt; p encoder_out.shape
torch.Size([4, 196, 2048])
ipdb&gt; encoded_captions.shape
torch.Size([4, 52])
ipdb&gt; encoded_captions[0]
tensor([2631,  226,   37,    8, 2630, 1832, 2632,    0,    0,    0,    0,    0,
           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
           0,    0,    0,    0])
ipdb&gt; n
&gt; <span class="ansi-green-fg">&lt;ipython-input-1-ffe59a3ddac7&gt;</span>(136)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">    134 </span>
<span class="ansi-green-fg">    135 </span><span class="ansi-red-fg">        </span><span class="ansi-red-fg"># Embedding</span>
<span class="ansi-green-fg">--&gt; 136 </span><span class="ansi-red-fg">        </span>embeddings <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>embedding<span class="ansi-blue-fg">(</span>encoded_captions<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, max_caption_length, embed_dim)</span>
<span class="ansi-green-fg">    137 </span>
<span class="ansi-green-fg">    138 </span><span class="ansi-red-fg">        </span><span class="ansi-red-fg"># Initialize LSTM state</span>

ipdb&gt; encoded_captions
tensor([[2631,    1,   99,   67,    1,   72,  296,   85,  402,    8,    9, 1218,
          365,    8, 1334, 2632,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0],
        [2631,    1,   46,  140,  285,   27,  198,  745,   78, 1783, 2632,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0],
        [2631,  235,  288,   83, 1471,    8,    1,  370, 2632,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0],
        [2631,  226,   37,    8, 2630, 1832, 2632,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
            0,    0,    0,    0]])
ipdb&gt; n
&gt; <span class="ansi-green-fg">&lt;ipython-input-1-ffe59a3ddac7&gt;</span>(139)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">    137 </span>
<span class="ansi-green-fg">    138 </span><span class="ansi-red-fg">        </span><span class="ansi-red-fg"># Initialize LSTM state</span>
<span class="ansi-green-fg">--&gt; 139 </span><span class="ansi-red-fg">        </span>h<span class="ansi-blue-fg">,</span> c <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>init_hidden_state<span class="ansi-blue-fg">(</span>encoder_out<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, decoder_dim)</span>
<span class="ansi-green-fg">    140 </span>
<span class="ansi-green-fg">    141 </span><span class="ansi-red-fg">        </span><span class="ansi-red-fg"># We won&#39;t decode at the &lt;end&gt; position, since we&#39;ve finished generating as soon as we generate &lt;end&gt;</span>

ipdb&gt; p encoder_out.shape
torch.Size([4, 196, 2048])
ipdb&gt; p h.shape
*** NameError: name &#39;h&#39; is not defined
ipdb&gt; n
&gt; <span class="ansi-green-fg">&lt;ipython-input-1-ffe59a3ddac7&gt;</span>(143)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">    141 </span><span class="ansi-red-fg">        </span><span class="ansi-red-fg"># We won&#39;t decode at the &lt;end&gt; position, since we&#39;ve finished generating as soon as we generate &lt;end&gt;</span>
<span class="ansi-green-fg">    142 </span><span class="ansi-red-fg">        </span><span class="ansi-red-fg"># So, decoding lengths are actual lengths - 1</span>
<span class="ansi-green-fg">--&gt; 143 </span><span class="ansi-red-fg">        </span>decode_lengths <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">(</span>caption_lengths <span class="ansi-blue-fg">-</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>tolist<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">    144 </span>
<span class="ansi-green-fg">    145 </span><span class="ansi-red-fg">        </span><span class="ansi-red-fg"># Create tensors to hold word predicion scores and alphas</span>

ipdb&gt; p h.shape
torch.Size([4, 512])
ipdb&gt; p c.shape
torch.Size([4, 512])
ipdb&gt; p self.init_h
Linear(in_features=2048, out_features=512, bias=True)
ipdb&gt; p encoder_out.mean(dim=1).shape
torch.Size([4, 2048])
ipdb&gt; encoder_out.shape
torch.Size([4, 196, 2048])
ipdb&gt; n
&gt; <span class="ansi-green-fg">&lt;ipython-input-1-ffe59a3ddac7&gt;</span>(146)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">    144 </span>
<span class="ansi-green-fg">    145 </span><span class="ansi-red-fg">        </span><span class="ansi-red-fg"># Create tensors to hold word predicion scores and alphas</span>
<span class="ansi-green-fg">--&gt; 146 </span><span class="ansi-red-fg">        </span>predictions <span class="ansi-blue-fg">=</span> torch<span class="ansi-blue-fg">.</span>zeros<span class="ansi-blue-fg">(</span>batch_size<span class="ansi-blue-fg">,</span> max<span class="ansi-blue-fg">(</span>decode_lengths<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> vocab_size<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>to<span class="ansi-blue-fg">(</span>device<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">    147 </span><span class="ansi-red-fg">        </span>alphas <span class="ansi-blue-fg">=</span> torch<span class="ansi-blue-fg">.</span>zeros<span class="ansi-blue-fg">(</span>batch_size<span class="ansi-blue-fg">,</span> max<span class="ansi-blue-fg">(</span>decode_lengths<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> num_pixels<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>to<span class="ansi-blue-fg">(</span>device<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">    148 </span>

ipdb&gt; n
&gt; <span class="ansi-green-fg">&lt;ipython-input-1-ffe59a3ddac7&gt;</span>(147)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">    145 </span><span class="ansi-red-fg">        </span><span class="ansi-red-fg"># Create tensors to hold word predicion scores and alphas</span>
<span class="ansi-green-fg">    146 </span><span class="ansi-red-fg">        </span>predictions <span class="ansi-blue-fg">=</span> torch<span class="ansi-blue-fg">.</span>zeros<span class="ansi-blue-fg">(</span>batch_size<span class="ansi-blue-fg">,</span> max<span class="ansi-blue-fg">(</span>decode_lengths<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> vocab_size<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>to<span class="ansi-blue-fg">(</span>device<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 147 </span><span class="ansi-red-fg">        </span>alphas <span class="ansi-blue-fg">=</span> torch<span class="ansi-blue-fg">.</span>zeros<span class="ansi-blue-fg">(</span>batch_size<span class="ansi-blue-fg">,</span> max<span class="ansi-blue-fg">(</span>decode_lengths<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> num_pixels<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>to<span class="ansi-blue-fg">(</span>device<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">    148 </span>
<span class="ansi-green-fg">    149 </span><span class="ansi-red-fg">        </span><span class="ansi-red-fg"># At each time-step, decode by</span>

ipdb&gt; n
&gt; <span class="ansi-green-fg">&lt;ipython-input-1-ffe59a3ddac7&gt;</span>(152)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">    150 </span><span class="ansi-red-fg">        </span><span class="ansi-red-fg"># attention-weighing the encoder&#39;s output based on the decoder&#39;s previous hidden state output</span>
<span class="ansi-green-fg">    151 </span><span class="ansi-red-fg">        </span><span class="ansi-red-fg"># then generate a new word in the decoder with the previous word and the attention weighted encoding</span>
<span class="ansi-green-fg">--&gt; 152 </span><span class="ansi-red-fg">        </span><span class="ansi-green-fg">for</span> t <span class="ansi-green-fg">in</span> range<span class="ansi-blue-fg">(</span>max<span class="ansi-blue-fg">(</span>decode_lengths<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">    153 </span><span class="ansi-red-fg">            </span>batch_size_t <span class="ansi-blue-fg">=</span> sum<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">[</span>l <span class="ansi-blue-fg">&gt;</span> t <span class="ansi-green-fg">for</span> l <span class="ansi-green-fg">in</span> decode_lengths<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">    154 </span><span class="ansi-red-fg">            attention_weighted_encoding, alpha = self.attention(encoder_out[:batch_size_t],
</span>
ipdb&gt; decode_lengths
[15, 10, 8, 6]
ipdb&gt; n
&gt; <span class="ansi-green-fg">&lt;ipython-input-1-ffe59a3ddac7&gt;</span>(153)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">    151 </span><span class="ansi-red-fg">        </span><span class="ansi-red-fg"># then generate a new word in the decoder with the previous word and the attention weighted encoding</span>
<span class="ansi-green-fg">    152 </span><span class="ansi-red-fg">        </span><span class="ansi-green-fg">for</span> t <span class="ansi-green-fg">in</span> range<span class="ansi-blue-fg">(</span>max<span class="ansi-blue-fg">(</span>decode_lengths<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 153 </span><span class="ansi-red-fg">            </span>batch_size_t <span class="ansi-blue-fg">=</span> sum<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">[</span>l <span class="ansi-blue-fg">&gt;</span> t <span class="ansi-green-fg">for</span> l <span class="ansi-green-fg">in</span> decode_lengths<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">    154 </span><span class="ansi-red-fg">            attention_weighted_encoding, alpha = self.attention(encoder_out[:batch_size_t],
</span><span class="ansi-green-fg">    155 </span><span class="ansi-red-fg">                                                                h[:batch_size_t])
</span>
ipdb&gt; n
&gt; <span class="ansi-green-fg">&lt;ipython-input-1-ffe59a3ddac7&gt;</span>(154)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">    152 </span><span class="ansi-red-fg">        </span><span class="ansi-green-fg">for</span> t <span class="ansi-green-fg">in</span> range<span class="ansi-blue-fg">(</span>max<span class="ansi-blue-fg">(</span>decode_lengths<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">    153 </span><span class="ansi-red-fg">            </span>batch_size_t <span class="ansi-blue-fg">=</span> sum<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">[</span>l <span class="ansi-blue-fg">&gt;</span> t <span class="ansi-green-fg">for</span> l <span class="ansi-green-fg">in</span> decode_lengths<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 154 </span><span class="ansi-red-fg">            attention_weighted_encoding, alpha = self.attention(encoder_out[:batch_size_t],
</span><span class="ansi-green-fg">    155 </span><span class="ansi-red-fg">                                                                h[:batch_size_t])
</span><span class="ansi-green-fg">    156 </span><span class="ansi-red-fg">            </span>gate <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>sigmoid<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>f_beta<span class="ansi-blue-fg">(</span>h<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">:</span>batch_size_t<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># gating scalar, (batch_size_t, encoder_dim)</span>

ipdb&gt; batch_size_t
4
ipdb&gt; encoder_out[:batch_size_t]
tensor([[[0.6308, 0.2627, 1.0739,  ..., 2.4373, 0.0000, 1.9724],
         [0.8419, 0.1314, 0.8361,  ..., 1.8396, 0.0000, 2.0814],
         [1.0529, 0.0000, 0.5982,  ..., 1.2419, 0.0000, 2.1903],
         ...,
         [1.4476, 1.2110, 0.6076,  ..., 3.1301, 0.1678, 0.5436],
         [1.8726, 1.1007, 0.7514,  ..., 2.8805, 0.8075, 1.8848],
         [2.2976, 0.9904, 0.8953,  ..., 2.6309, 1.4473, 3.2261]],

        [[0.6308, 0.2627, 1.0739,  ..., 2.4373, 0.0000, 1.9724],
         [0.8419, 0.1314, 0.8361,  ..., 1.8396, 0.0000, 2.0814],
         [1.0529, 0.0000, 0.5982,  ..., 1.2419, 0.0000, 2.1903],
         ...,
         [1.4476, 1.2110, 0.6076,  ..., 3.1301, 0.1678, 0.5436],
         [1.8726, 1.1007, 0.7514,  ..., 2.8805, 0.8075, 1.8848],
         [2.2976, 0.9904, 0.8953,  ..., 2.6309, 1.4473, 3.2261]],

        [[0.6308, 0.2627, 1.0739,  ..., 2.4373, 0.0000, 1.9724],
         [0.8419, 0.1314, 0.8361,  ..., 1.8396, 0.0000, 2.0814],
         [1.0529, 0.0000, 0.5982,  ..., 1.2419, 0.0000, 2.1903],
         ...,
         [1.4476, 1.2110, 0.6076,  ..., 3.1301, 0.1678, 0.5436],
         [1.8726, 1.1007, 0.7514,  ..., 2.8805, 0.8075, 1.8848],
         [2.2976, 0.9904, 0.8953,  ..., 2.6309, 1.4473, 3.2261]],

        [[0.6308, 0.2627, 1.0739,  ..., 2.4373, 0.0000, 1.9724],
         [0.8419, 0.1314, 0.8361,  ..., 1.8396, 0.0000, 2.0814],
         [1.0529, 0.0000, 0.5982,  ..., 1.2419, 0.0000, 2.1903],
         ...,
         [1.4476, 1.2110, 0.6076,  ..., 3.1301, 0.1678, 0.5436],
         [1.8726, 1.1007, 0.7514,  ..., 2.8805, 0.8075, 1.8848],
         [2.2976, 0.9904, 0.8953,  ..., 2.6309, 1.4473, 3.2261]]])
ipdb&gt; encoder_out[:batch_size_t].shape
torch.Size([4, 196, 2048])
ipdb&gt; h[:batch_size_t].shape
*** No help for &#39;[:batch_size_t].shape&#39;
ipdb&gt; p h[:batch_size_t].shape
torch.Size([4, 512])
ipdb&gt; c
&gt; <span class="ansi-green-fg">&lt;ipython-input-1-ffe59a3ddac7&gt;</span>(35)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">     33 </span><span class="ansi-red-fg">        &#34;&#34;&#34;
</span><span class="ansi-green-fg">     34 </span><span class="ansi-red-fg">        </span><span class="ansi-green-fg">import</span> pdb<span class="ansi-blue-fg">;</span>pdb<span class="ansi-blue-fg">.</span>set_trace<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 35 </span><span class="ansi-red-fg">        </span>att1 <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>encoder_att<span class="ansi-blue-fg">(</span>encoder_out<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels, attention_dim)</span>
<span class="ansi-green-fg">     36 </span><span class="ansi-red-fg">        </span>att2 <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>decoder_att<span class="ansi-blue-fg">(</span>decoder_hidden<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, attention_dim)</span>
<span class="ansi-green-fg">     37 </span><span class="ansi-red-fg">        </span>att <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>full_att<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>relu<span class="ansi-blue-fg">(</span>att1 <span class="ansi-blue-fg">+</span> att2<span class="ansi-blue-fg">.</span>unsqueeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>squeeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels)</span>

ipdb&gt; p encoder_out.shape
torch.Size([4, 196, 2048])
ipdb&gt; n
&gt; <span class="ansi-green-fg">&lt;ipython-input-1-ffe59a3ddac7&gt;</span>(36)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">     34 </span><span class="ansi-red-fg">        </span><span class="ansi-green-fg">import</span> pdb<span class="ansi-blue-fg">;</span>pdb<span class="ansi-blue-fg">.</span>set_trace<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">     35 </span><span class="ansi-red-fg">        </span>att1 <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>encoder_att<span class="ansi-blue-fg">(</span>encoder_out<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels, attention_dim)</span>
<span class="ansi-green-fg">---&gt; 36 </span><span class="ansi-red-fg">        </span>att2 <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>decoder_att<span class="ansi-blue-fg">(</span>decoder_hidden<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, attention_dim)</span>
<span class="ansi-green-fg">     37 </span><span class="ansi-red-fg">        </span>att <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>full_att<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>relu<span class="ansi-blue-fg">(</span>att1 <span class="ansi-blue-fg">+</span> att2<span class="ansi-blue-fg">.</span>unsqueeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>squeeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels)</span>
<span class="ansi-green-fg">     38 </span><span class="ansi-red-fg">        </span>alpha <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>softmax<span class="ansi-blue-fg">(</span>att<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels)</span>

ipdb&gt; p att1.shape
torch.Size([4, 196, 512])
ipdb&gt; p decoder_hidden.shape
torch.Size([4, 512])
ipdb&gt; n
&gt; <span class="ansi-green-fg">&lt;ipython-input-1-ffe59a3ddac7&gt;</span>(37)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">     35 </span><span class="ansi-red-fg">        </span>att1 <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>encoder_att<span class="ansi-blue-fg">(</span>encoder_out<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels, attention_dim)</span>
<span class="ansi-green-fg">     36 </span><span class="ansi-red-fg">        </span>att2 <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>decoder_att<span class="ansi-blue-fg">(</span>decoder_hidden<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, attention_dim)</span>
<span class="ansi-green-fg">---&gt; 37 </span><span class="ansi-red-fg">        </span>att <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>full_att<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>relu<span class="ansi-blue-fg">(</span>att1 <span class="ansi-blue-fg">+</span> att2<span class="ansi-blue-fg">.</span>unsqueeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>squeeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels)</span>
<span class="ansi-green-fg">     38 </span><span class="ansi-red-fg">        </span>alpha <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>softmax<span class="ansi-blue-fg">(</span>att<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels)</span>
<span class="ansi-green-fg">     39 </span><span class="ansi-red-fg">        </span>attention_weighted_encoding <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">(</span>encoder_out <span class="ansi-blue-fg">*</span> alpha<span class="ansi-blue-fg">.</span>unsqueeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>sum<span class="ansi-blue-fg">(</span>dim<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, encoder_dim)</span>

ipdb&gt; p att2.shape
torch.Size([4, 512])
ipdb&gt; p att1.shape
torch.Size([4, 196, 512])
ipdb&gt; self.relu(att1 + att2.unsqueeze(1))
tensor([[[0.9818, 0.0000, 1.0762,  ..., 0.0000, 1.2722, 1.0555],
         [0.8515, 0.0000, 1.2245,  ..., 0.0000, 1.7601, 1.1482],
         [0.7212, 0.0000, 1.3729,  ..., 0.0000, 2.2480, 1.2408],
         ...,
         [0.0000, 0.7818, 0.0000,  ..., 0.2425, 1.2898, 1.3694],
         [0.0000, 0.4922, 0.0000,  ..., 0.3724, 1.5495, 1.5270],
         [0.0000, 0.2026, 0.1286,  ..., 0.5024, 1.8092, 1.6846]],

        [[0.9818, 0.0000, 1.0762,  ..., 0.0000, 1.2722, 1.0555],
         [0.8515, 0.0000, 1.2245,  ..., 0.0000, 1.7601, 1.1482],
         [0.7212, 0.0000, 1.3729,  ..., 0.0000, 2.2480, 1.2408],
         ...,
         [0.0000, 0.7818, 0.0000,  ..., 0.2425, 1.2898, 1.3694],
         [0.0000, 0.4922, 0.0000,  ..., 0.3724, 1.5495, 1.5270],
         [0.0000, 0.2026, 0.1286,  ..., 0.5024, 1.8092, 1.6846]],

        [[0.9818, 0.0000, 1.0762,  ..., 0.0000, 1.2722, 1.0555],
         [0.8515, 0.0000, 1.2245,  ..., 0.0000, 1.7601, 1.1482],
         [0.7212, 0.0000, 1.3729,  ..., 0.0000, 2.2480, 1.2408],
         ...,
         [0.0000, 0.7818, 0.0000,  ..., 0.2425, 1.2898, 1.3694],
         [0.0000, 0.4922, 0.0000,  ..., 0.3724, 1.5495, 1.5270],
         [0.0000, 0.2026, 0.1286,  ..., 0.5024, 1.8092, 1.6846]],

        [[0.9818, 0.0000, 1.0762,  ..., 0.0000, 1.2722, 1.0555],
         [0.8515, 0.0000, 1.2245,  ..., 0.0000, 1.7601, 1.1482],
         [0.7212, 0.0000, 1.3729,  ..., 0.0000, 2.2480, 1.2408],
         ...,
         [0.0000, 0.7818, 0.0000,  ..., 0.2425, 1.2898, 1.3694],
         [0.0000, 0.4922, 0.0000,  ..., 0.3724, 1.5495, 1.5270],
         [0.0000, 0.2026, 0.1286,  ..., 0.5024, 1.8092, 1.6846]]],
       grad_fn=&lt;ReluBackward0&gt;)
ipdb&gt; self.relu(att1 + att2.unsqueeze(1)).shap
*** AttributeError: &#39;Tensor&#39; object has no attribute &#39;shap&#39;
ipdb&gt; self.relu(att1 + att2.unsqueeze(1)).shape
torch.Size([4, 196, 512])
ipdb&gt; att1.shape
torch.Size([4, 196, 512])
ipdb&gt; att2.shape
torch.Size([4, 512])
ipdb&gt; att2.unsqueeze(1).shape
torch.Size([4, 1, 512])
ipdb&gt; p (att1 + att2.unsqueeze(1)).shape
torch.Size([4, 196, 512])
ipdb&gt; n
&gt; <span class="ansi-green-fg">&lt;ipython-input-1-ffe59a3ddac7&gt;</span>(38)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">     36 </span><span class="ansi-red-fg">        </span>att2 <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>decoder_att<span class="ansi-blue-fg">(</span>decoder_hidden<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, attention_dim)</span>
<span class="ansi-green-fg">     37 </span><span class="ansi-red-fg">        </span>att <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>full_att<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>relu<span class="ansi-blue-fg">(</span>att1 <span class="ansi-blue-fg">+</span> att2<span class="ansi-blue-fg">.</span>unsqueeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>squeeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels)</span>
<span class="ansi-green-fg">---&gt; 38 </span><span class="ansi-red-fg">        </span>alpha <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>softmax<span class="ansi-blue-fg">(</span>att<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels)</span>
<span class="ansi-green-fg">     39 </span><span class="ansi-red-fg">        </span>attention_weighted_encoding <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">(</span>encoder_out <span class="ansi-blue-fg">*</span> alpha<span class="ansi-blue-fg">.</span>unsqueeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>sum<span class="ansi-blue-fg">(</span>dim<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, encoder_dim)</span>
<span class="ansi-green-fg">     40 </span>

ipdb&gt; p att.shape
torch.Size([4, 196])
ipdb&gt; p self.relu(att1 + att2.unsqueeze(1)).shape
torch.Size([4, 196, 512])
ipdb&gt; p att.shape
torch.Size([4, 196])
ipdb&gt; p self.full_att(self.relu(att1 + att2.unsqueeze(1))).shape
torch.Size([4, 196, 1])
ipdb&gt; p alpha = self.softmax(att)
*** SyntaxError: invalid syntax
ipdb&gt; n
&gt; <span class="ansi-green-fg">&lt;ipython-input-1-ffe59a3ddac7&gt;</span>(39)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">     37 </span><span class="ansi-red-fg">        </span>att <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>full_att<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>relu<span class="ansi-blue-fg">(</span>att1 <span class="ansi-blue-fg">+</span> att2<span class="ansi-blue-fg">.</span>unsqueeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>squeeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels)</span>
<span class="ansi-green-fg">     38 </span><span class="ansi-red-fg">        </span>alpha <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>softmax<span class="ansi-blue-fg">(</span>att<span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, num_pixels)</span>
<span class="ansi-green-fg">---&gt; 39 </span><span class="ansi-red-fg">        </span>attention_weighted_encoding <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">(</span>encoder_out <span class="ansi-blue-fg">*</span> alpha<span class="ansi-blue-fg">.</span>unsqueeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>sum<span class="ansi-blue-fg">(</span>dim<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, encoder_dim)</span>
<span class="ansi-green-fg">     40 </span>
<span class="ansi-green-fg">     41 </span><span class="ansi-red-fg">        </span><span class="ansi-green-fg">return</span> attention_weighted_encoding<span class="ansi-blue-fg">,</span> alpha

ipdb&gt; p encoder_out.shape
torch.Size([4, 196, 2048])
ipdb&gt; p alpha.shape
torch.Size([4, 196])
ipdb&gt; p alpha[0].sum()
tensor(1.0000, grad_fn=&lt;SumBackward0&gt;)
ipdb&gt; p alpha[0]
tensor([0.0059, 0.0061, 0.0065, 0.0062, 0.0062, 0.0057, 0.0052, 0.0052, 0.0053,
        0.0055, 0.0053, 0.0054, 0.0047, 0.0040, 0.0057, 0.0057, 0.0059, 0.0056,
        0.0054, 0.0052, 0.0052, 0.0053, 0.0050, 0.0049, 0.0049, 0.0047, 0.0043,
        0.0038, 0.0053, 0.0054, 0.0055, 0.0051, 0.0049, 0.0049, 0.0051, 0.0056,
        0.0049, 0.0046, 0.0045, 0.0042, 0.0040, 0.0039, 0.0062, 0.0058, 0.0055,
        0.0052, 0.0050, 0.0049, 0.0049, 0.0054, 0.0049, 0.0046, 0.0046, 0.0046,
        0.0046, 0.0043, 0.0070, 0.0063, 0.0054, 0.0051, 0.0051, 0.0050, 0.0048,
        0.0049, 0.0048, 0.0047, 0.0047, 0.0046, 0.0046, 0.0045, 0.0064, 0.0060,
        0.0057, 0.0051, 0.0048, 0.0047, 0.0046, 0.0048, 0.0048, 0.0046, 0.0047,
        0.0049, 0.0049, 0.0049, 0.0059, 0.0056, 0.0055, 0.0050, 0.0045, 0.0044,
        0.0045, 0.0047, 0.0046, 0.0045, 0.0049, 0.0054, 0.0053, 0.0055, 0.0055,
        0.0055, 0.0057, 0.0052, 0.0050, 0.0048, 0.0047, 0.0046, 0.0048, 0.0049,
        0.0050, 0.0052, 0.0053, 0.0054, 0.0054, 0.0053, 0.0054, 0.0051, 0.0049,
        0.0049, 0.0049, 0.0049, 0.0050, 0.0050, 0.0048, 0.0048, 0.0050, 0.0052,
        0.0053, 0.0051, 0.0051, 0.0049, 0.0048, 0.0049, 0.0051, 0.0053, 0.0053,
        0.0052, 0.0048, 0.0045, 0.0047, 0.0049, 0.0065, 0.0063, 0.0059, 0.0055,
        0.0052, 0.0051, 0.0050, 0.0049, 0.0049, 0.0049, 0.0044, 0.0043, 0.0044,
        0.0046, 0.0077, 0.0072, 0.0068, 0.0062, 0.0055, 0.0052, 0.0050, 0.0049,
        0.0047, 0.0046, 0.0042, 0.0040, 0.0043, 0.0045, 0.0077, 0.0070, 0.0065,
        0.0062, 0.0056, 0.0052, 0.0048, 0.0048, 0.0045, 0.0043, 0.0040, 0.0038,
        0.0037, 0.0038, 0.0079, 0.0068, 0.0060, 0.0061, 0.0058, 0.0053, 0.0049,
        0.0047, 0.0043, 0.0040, 0.0038, 0.0036, 0.0033, 0.0031],
       grad_fn=&lt;SelectBackward&gt;)
ipdb&gt; n
&gt; <span class="ansi-green-fg">&lt;ipython-input-1-ffe59a3ddac7&gt;</span>(41)<span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-fg">     39 </span><span class="ansi-red-fg">        </span>attention_weighted_encoding <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">(</span>encoder_out <span class="ansi-blue-fg">*</span> alpha<span class="ansi-blue-fg">.</span>unsqueeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>sum<span class="ansi-blue-fg">(</span>dim<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, encoder_dim)</span>
<span class="ansi-green-fg">     40 </span>
<span class="ansi-green-fg">---&gt; 41 </span><span class="ansi-red-fg">        </span><span class="ansi-green-fg">return</span> attention_weighted_encoding<span class="ansi-blue-fg">,</span> alpha
<span class="ansi-green-fg">     42 </span>
<span class="ansi-green-fg">     43 </span>

ipdb&gt; q
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">BdbQuit</span>                                   Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-12-cb665db24f90&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">     20</span>           encoder_optimizer<span class="ansi-blue-fg">=</span>encoder_optimizer<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">     21</span>           decoder_optimizer<span class="ansi-blue-fg">=</span>decoder_optimizer<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">---&gt; 22</span><span class="ansi-red-fg">           epoch=epoch)
</span>
<span class="ansi-green-fg">&lt;ipython-input-7-3cbbf1757317&gt;</span> in <span class="ansi-cyan-fg">train</span><span class="ansi-blue-fg">(train_loader, encoder, decoder, criterion, encoder_optimizer, decoder_optimizer, epoch)</span>
<span class="ansi-green-intense-fg ansi-bold">     31</span>         <span class="ansi-red-fg"># Forward prop.</span>
<span class="ansi-green-intense-fg ansi-bold">     32</span>         imgs <span class="ansi-blue-fg">=</span> encoder<span class="ansi-blue-fg">(</span>imgs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 33</span><span class="ansi-red-fg">         </span>scores<span class="ansi-blue-fg">,</span> caps_sorted<span class="ansi-blue-fg">,</span> decode_lengths<span class="ansi-blue-fg">,</span> alphas<span class="ansi-blue-fg">,</span> sort_ind <span class="ansi-blue-fg">=</span> decoder<span class="ansi-blue-fg">(</span>imgs<span class="ansi-blue-fg">,</span> caps<span class="ansi-blue-fg">,</span> caplens<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     34</span> 
<span class="ansi-green-intense-fg ansi-bold">     35</span>         <span class="ansi-red-fg"># Since we decoded starting with &lt;start&gt;, the targets are all words after &lt;start&gt;, up to &lt;end&gt;</span>

<span class="ansi-green-fg">~/anaconda3/envs/my_env/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    530</span>             result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_slow_forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    531</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 532</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    533</span>         <span class="ansi-green-fg">for</span> hook <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">.</span>_forward_hooks<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    534</span>             hook_result <span class="ansi-blue-fg">=</span> hook<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> input<span class="ansi-blue-fg">,</span> result<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-1-ffe59a3ddac7&gt;</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, encoder_out, encoded_captions, caption_lengths)</span>
<span class="ansi-green-intense-fg ansi-bold">    152</span>         <span class="ansi-green-fg">for</span> t <span class="ansi-green-fg">in</span> range<span class="ansi-blue-fg">(</span>max<span class="ansi-blue-fg">(</span>decode_lengths<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    153</span>             batch_size_t <span class="ansi-blue-fg">=</span> sum<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">[</span>l <span class="ansi-blue-fg">&gt;</span> t <span class="ansi-green-fg">for</span> l <span class="ansi-green-fg">in</span> decode_lengths<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 154</span><span class="ansi-red-fg">             attention_weighted_encoding, alpha = self.attention(encoder_out[:batch_size_t],
</span><span class="ansi-green-intense-fg ansi-bold">    155</span>                                                                 h[:batch_size_t])
<span class="ansi-green-intense-fg ansi-bold">    156</span>             gate <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>sigmoid<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>f_beta<span class="ansi-blue-fg">(</span>h<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">:</span>batch_size_t<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># gating scalar, (batch_size_t, encoder_dim)</span>

<span class="ansi-green-fg">~/anaconda3/envs/my_env/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, *input, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    530</span>             result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_slow_forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    531</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 532</span><span class="ansi-red-fg">             </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>forward<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>input<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    533</span>         <span class="ansi-green-fg">for</span> hook <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">.</span>_forward_hooks<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    534</span>             hook_result <span class="ansi-blue-fg">=</span> hook<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> input<span class="ansi-blue-fg">,</span> result<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">&lt;ipython-input-1-ffe59a3ddac7&gt;</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, encoder_out, decoder_hidden)</span>
<span class="ansi-green-intense-fg ansi-bold">     39</span>         attention_weighted_encoding <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">(</span>encoder_out <span class="ansi-blue-fg">*</span> alpha<span class="ansi-blue-fg">.</span>unsqueeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>sum<span class="ansi-blue-fg">(</span>dim<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, encoder_dim)</span>
<span class="ansi-green-intense-fg ansi-bold">     40</span> 
<span class="ansi-green-fg">---&gt; 41</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> attention_weighted_encoding<span class="ansi-blue-fg">,</span> alpha
<span class="ansi-green-intense-fg ansi-bold">     42</span> 
<span class="ansi-green-intense-fg ansi-bold">     43</span> 

<span class="ansi-green-fg">&lt;ipython-input-1-ffe59a3ddac7&gt;</span> in <span class="ansi-cyan-fg">forward</span><span class="ansi-blue-fg">(self, encoder_out, decoder_hidden)</span>
<span class="ansi-green-intense-fg ansi-bold">     39</span>         attention_weighted_encoding <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">(</span>encoder_out <span class="ansi-blue-fg">*</span> alpha<span class="ansi-blue-fg">.</span>unsqueeze<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>sum<span class="ansi-blue-fg">(</span>dim<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>  <span class="ansi-red-fg"># (batch_size, encoder_dim)</span>
<span class="ansi-green-intense-fg ansi-bold">     40</span> 
<span class="ansi-green-fg">---&gt; 41</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> attention_weighted_encoding<span class="ansi-blue-fg">,</span> alpha
<span class="ansi-green-intense-fg ansi-bold">     42</span> 
<span class="ansi-green-intense-fg ansi-bold">     43</span> 

<span class="ansi-green-fg">~/anaconda3/envs/my_env/lib/python3.7/bdb.py</span> in <span class="ansi-cyan-fg">trace_dispatch</span><span class="ansi-blue-fg">(self, frame, event, arg)</span>
<span class="ansi-green-intense-fg ansi-bold">     86</span>             <span class="ansi-green-fg">return</span> <span class="ansi-red-fg"># None</span>
<span class="ansi-green-intense-fg ansi-bold">     87</span>         <span class="ansi-green-fg">if</span> event <span class="ansi-blue-fg">==</span> <span class="ansi-blue-fg">&#39;line&#39;</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 88</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>dispatch_line<span class="ansi-blue-fg">(</span>frame<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     89</span>         <span class="ansi-green-fg">if</span> event <span class="ansi-blue-fg">==</span> <span class="ansi-blue-fg">&#39;call&#39;</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     90</span>             <span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>dispatch_call<span class="ansi-blue-fg">(</span>frame<span class="ansi-blue-fg">,</span> arg<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/anaconda3/envs/my_env/lib/python3.7/bdb.py</span> in <span class="ansi-cyan-fg">dispatch_line</span><span class="ansi-blue-fg">(self, frame)</span>
<span class="ansi-green-intense-fg ansi-bold">    111</span>         <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>stop_here<span class="ansi-blue-fg">(</span>frame<span class="ansi-blue-fg">)</span> <span class="ansi-green-fg">or</span> self<span class="ansi-blue-fg">.</span>break_here<span class="ansi-blue-fg">(</span>frame<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    112</span>             self<span class="ansi-blue-fg">.</span>user_line<span class="ansi-blue-fg">(</span>frame<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 113</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>quitting<span class="ansi-blue-fg">:</span> <span class="ansi-green-fg">raise</span> BdbQuit
<span class="ansi-green-intense-fg ansi-bold">    114</span>         <span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>trace_dispatch
<span class="ansi-green-intense-fg ansi-bold">    115</span> 

<span class="ansi-red-fg">BdbQuit</span>: </pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

